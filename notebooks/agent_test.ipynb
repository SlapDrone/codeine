{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "138b3640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import inspect\n",
    "import typing as ty\n",
    "from functools import wraps\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import aioitertools\n",
    "from langchain.input import get_color_mapping\n",
    "from langchain.agents import AgentExecutor, Tool\n",
    "from langchain.agents.agent import AgentAction, AgentFinish\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForChainRun, Callbacks, CallbackManager, AsyncCallbackManager\n",
    ")\n",
    "from langchain.utilities.asyncio import asyncio_timeout\n",
    "from langchain.load.dump import dumpd\n",
    "from langchain.schema import RUN_KEY, RunInfo\n",
    "sys.path.insert(0, \"..\")\n",
    "from codeine.chatbot import build_chat_engine, service_context\n",
    "\n",
    "level = logging.DEBUG\n",
    "#level = logging.INFO\n",
    "logging.basicConfig(level=level)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(level)\n",
    "\n",
    "chat_engine = build_chat_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a18a4b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_callback_manager_on_set(\n",
    "    setter_method: ty.Callable[..., None]\n",
    ") -> ty.Callable[..., None]:\n",
    "    \"\"\"Decorator to force setters to rebuild callback mgr\"\"\"\n",
    "    @wraps(setter_method)\n",
    "    def wrapper(self: ty.Any, *args: ty.Any, **kwargs: ty.Any) -> None:\n",
    "        setter_method(self, *args, **kwargs)\n",
    "        self.build_callback_manager()\n",
    "    return wrapper\n",
    "\n",
    "class AgentExecutorIterator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        agent_executor: AgentExecutor,\n",
    "        inputs: dict[str, str] | str,\n",
    "        callbacks: Callbacks = None,\n",
    "        *,\n",
    "        tags: list[str] | None = None,\n",
    "        include_run_info: bool = False,\n",
    "        async_: bool = False\n",
    "    ):\n",
    "        self._agent_executor = agent_executor\n",
    "        self.inputs = inputs\n",
    "        self.async_ = async_\n",
    "        # build callback manager on tags setter\n",
    "        self._callbacks = callbacks\n",
    "        self.tags = tags \n",
    "        self.include_run_info = include_run_info\n",
    "        self.run_manager = None\n",
    "    \n",
    "    @property\n",
    "    def inputs(self) -> dict[str, str]:\n",
    "        return self._inputs\n",
    "    \n",
    "    @inputs.setter\n",
    "    def inputs(self, inputs: dict[str, str] | str) -> None:\n",
    "        self._inputs = self.agent_executor.prep_inputs(inputs)\n",
    "    \n",
    "    @property\n",
    "    def callbacks(self):\n",
    "        return self._callbacks\n",
    "    \n",
    "    @property\n",
    "    def tags(self):\n",
    "        return self._tags\n",
    "    \n",
    "    @property\n",
    "    def agent_executor(self):\n",
    "        return self._agent_executor\n",
    "    \n",
    "    @callbacks.setter\n",
    "    @rebuild_callback_manager_on_set\n",
    "    def callbacks(self, callbacks: Callbacks) -> None:\n",
    "        \"\"\"When callbacks are changed after __init__, rebuild callback mgr\"\"\"\n",
    "        self._callbacks = callbacks\n",
    "    \n",
    "    @tags.setter\n",
    "    @rebuild_callback_manager_on_set\n",
    "    def tags(self, tags: list[str] | None) -> None:\n",
    "        \"\"\"When tags are changed after __init__, rebuild callback mgr\"\"\"\n",
    "        self._tags = tags\n",
    "    \n",
    "    @agent_executor.setter\n",
    "    @rebuild_callback_manager_on_set\n",
    "    def agent_executor(self, agent_executor: AgentExecutor) -> None:\n",
    "        self._agent_executor = agent_executor\n",
    "        # force re-prep inputs incase agent_executor's prep_inputs fn changed\n",
    "        self.inputs = self.inputs \n",
    "        \n",
    "    @property\n",
    "    def callback_manager(self) -> AsyncCallbackManager | CallbackManager:\n",
    "        return self._callback_manager\n",
    "    \n",
    "    def build_callback_manager(self) -> None:\n",
    "        CallbackMgr = AsyncCallbackManager if self.async_ else CallbackManager\n",
    "        self._callback_manager = CallbackMgr.configure(\n",
    "            self.callbacks,\n",
    "            self.agent_executor.callbacks,\n",
    "            self.agent_executor.verbose,\n",
    "            self.tags,\n",
    "            self.agent_executor.tags\n",
    "        )        \n",
    "\n",
    "    @property\n",
    "    def name_to_tool_map(self):\n",
    "        return {tool.name: tool for tool in self.agent_executor.tools}\n",
    "    \n",
    "    @property\n",
    "    def color_mapping(self):\n",
    "        return get_color_mapping(\n",
    "            [tool.name for tool in self.agent_executor.tools],\n",
    "            excluded_colors=[\"green\", \"red\"]\n",
    "        )\n",
    "    \n",
    "    def reset(self):\n",
    "        logger.debug(f\"(Re)setting AgentExecutorIterator to fresh state\")\n",
    "        self.intermediate_steps: list[tuple[AgentAction, str]] = []\n",
    "        self.iterations = 0\n",
    "        # maybe better to start these on the first __anext__ call?\n",
    "        self.time_elapsed = 0.0\n",
    "        self.start_time = time.time()\n",
    "        self._final_outputs = None\n",
    "        \n",
    "    def update_iterations(self):\n",
    "        self.iterations += 1\n",
    "        self.time_elapsed = time.time() - self.start_time\n",
    "        logger.debug(f\"Agent Iterations: {self.iterations} ({self.time_elapsed:.2f}s elapsed)\")\n",
    "\n",
    "    def raise_stopiteration(self, output: ty.Any):\n",
    "        logger.debug(\"Chain end: stop iteration\")\n",
    "        raise StopIteration(output)\n",
    "    \n",
    "    async def raise_stopasynciteration(self, output: ty.Any):\n",
    "        logger.debug(\"Chain end: stop async iteration\")\n",
    "        if self.timeout_manager is not None:\n",
    "            await self.timeout_manager.__aexit__(None, None, None)\n",
    "        raise StopAsyncIteration(output)\n",
    "    \n",
    "    @property\n",
    "    def final_outputs(self):\n",
    "        return self._final_outputs\n",
    "    \n",
    "    @final_outputs.setter\n",
    "    def final_outputs(self, outputs):\n",
    "        # have access to intermediate steps by design in iterator,\n",
    "        # so return only outputs may as well always be true.\n",
    "        final_outputs: dict[str, ty.Any] = self.agent_executor.prep_outputs(\n",
    "            self.inputs, outputs, return_only_outputs=True\n",
    "        )\n",
    "        if self.include_run_info and self.run_manager is not None:\n",
    "            logger.debug(\"Assign run key\")\n",
    "            final_outputs[RUN_KEY] = RunInfo(run_id=self.run_manager.run_id)\n",
    "        self._final_outputs = final_outputs\n",
    "    \n",
    "    def __iter__(self):\n",
    "        logger.debug(\"Initialising AgentExecutorIterator\")\n",
    "        self.reset()\n",
    "        self.run_manager = self.callback_manager.on_chain_start(\n",
    "            dumpd(self.agent_executor),\n",
    "            self.inputs,\n",
    "        )\n",
    "        return self\n",
    "    \n",
    "    def __aiter__(self):\n",
    "        \"\"\"\n",
    "        N.B. __aiter__ must be a normal method, so need to initialise async run manager \n",
    "        on first __anext__ call where we can await it\n",
    "        \"\"\"\n",
    "        logger.debug(\"Initialising AgentExecutorIterator (async)\")\n",
    "        self.reset()\n",
    "        if self.agent_executor.max_execution_time:\n",
    "            self.timeout_manager = asyncio_timeout(self.agent_executor.max_execution_time)\n",
    "        else:\n",
    "            self.timeout_manager = None\n",
    "        return self\n",
    "\n",
    "    def _on_first_step(self) -> None:\n",
    "        \"\"\"\n",
    "        In sync case, can put logic in __iter__ that we would need to instead put \n",
    "        in a coroutine function since __aiter__ is a normal method.\n",
    "        So this is a stub for sync/async symmetry at the moment.\n",
    "        \"\"\"\n",
    "        pass\n",
    "            \n",
    "    async def _on_first_async_step(self) -> None:\n",
    "        # on first step, need to await callback manager and start async timeout ctxmgr\n",
    "        if not self.iterations:\n",
    "            self.run_manager = await self.callback_manager.on_chain_start(\n",
    "                dumpd(self.agent_executor),\n",
    "                self.inputs,\n",
    "            )\n",
    "            if self.timeout_manager:\n",
    "                await self.timeout_manager.__aenter__()\n",
    "    \n",
    "    def __next__(self) -> dict[str, ty.Any]:\n",
    "        \"\"\"\n",
    "        AgentExecutor               AgentExecutorIterator\n",
    "        __call__                    (__iter__ ->) __next__\n",
    "            _call              <=>      _call_next\n",
    "                _take_next_step             _take_next_step   \n",
    "        \"\"\"\n",
    "        # first step\n",
    "        if not self.iterations:\n",
    "            self._on_first_step()\n",
    "        # N.B. timeout taken care of by \"_should_continue\" in sync case\n",
    "        try:\n",
    "            return self._call_next()\n",
    "        except (KeyboardInterrupt, Exception) as e:\n",
    "            self.run_manager.on_chain_error(e)\n",
    "            raise\n",
    "            \n",
    "    async def __anext__(self) -> dict[str, ty.Any]:\n",
    "        \"\"\"\n",
    "        AgentExecutor               AgentExecutorIterator\n",
    "        acall                       (__aiter__ ->) __anext__\n",
    "            _acall              <=>     _acall_next\n",
    "                _atake_next_step            _atake_next_step   \n",
    "        \"\"\"\n",
    "        if not self.iterations:\n",
    "            await self._on_first_async_step()\n",
    "        try:\n",
    "            return await self._acall_next()\n",
    "        except TimeoutError:\n",
    "            await self._astop()\n",
    "        except (KeyboardInterrupt, Exception) as e:\n",
    "            await self.run_manager.on_chain_error(e)\n",
    "            raise\n",
    "        \n",
    "    def _execute_next_step(self):\n",
    "        return self.agent_executor._take_next_step(\n",
    "            self.name_to_tool_map,\n",
    "            self.color_mapping,\n",
    "            self.inputs,\n",
    "            self.intermediate_steps,\n",
    "            run_manager=self.run_manager,\n",
    "        )\n",
    "\n",
    "    async def _execute_next_async_step(self):\n",
    "        return await self.agent_executor._atake_next_step(\n",
    "            self.name_to_tool_map,\n",
    "            self.color_mapping,\n",
    "            self.inputs,\n",
    "            self.intermediate_steps,\n",
    "            run_manager=self.run_manager,\n",
    "        )\n",
    "\n",
    "    def _process_next_step_output(self, next_step_output, run_manager):\n",
    "        logger.debug(\"Processing output of Agent loop step\")\n",
    "        if isinstance(next_step_output, AgentFinish):\n",
    "            logger.debug(f\"Hit AgentFinish: _return -> on_chain_end -> run final output logic\")\n",
    "            output = self.agent_executor._return(\n",
    "                next_step_output, self.intermediate_steps, run_manager=run_manager\n",
    "            )\n",
    "            if self.run_manager:\n",
    "                self.run_manager.on_chain_end(output)\n",
    "            self.final_outputs = output\n",
    "            return self.final_outputs\n",
    "\n",
    "        self.intermediate_steps.extend(next_step_output)\n",
    "        logger.debug(\"Updated intermediate_steps with step output\")\n",
    "\n",
    "        # Check for tool return\n",
    "        if len(next_step_output) == 1:\n",
    "            next_step_action = next_step_output[0]\n",
    "            tool_return = self.agent_executor._get_tool_return(next_step_action)\n",
    "            if tool_return is not None:\n",
    "                output = self.agent_executor._return(\n",
    "                    tool_return, self.intermediate_steps, run_manager=run_manager\n",
    "                )\n",
    "                if self.run_manager:\n",
    "                    self.run_manager.on_chain_end(output)\n",
    "                self.final_outputs = output\n",
    "                return self.final_outputs\n",
    "\n",
    "        output = {\"intermediate_steps\": self.intermediate_steps}\n",
    "        return output\n",
    "\n",
    "    async def _aprocess_next_step_output(self, next_step_output, run_manager):\n",
    "        logger.debug(\"Processing output of async Agent loop step\")\n",
    "        if isinstance(next_step_output, AgentFinish):\n",
    "            logger.debug(f\"Hit AgentFinish: _areturn -> on_chain_end -> run final output logic\")\n",
    "            output = await self.agent_executor._areturn(\n",
    "                next_step_output, self.intermediate_steps, run_manager=run_manager\n",
    "            )\n",
    "            if self.run_manager:\n",
    "                await self.run_manager.on_chain_end(output)\n",
    "            self.final_outputs = output\n",
    "            return self.final_outputs\n",
    "\n",
    "        self.intermediate_steps.extend(next_step_output)\n",
    "        logger.debug(\"Updated intermediate_steps with step output\")\n",
    "\n",
    "        # Check for tool return\n",
    "        if len(next_step_output) == 1:\n",
    "            next_step_action = next_step_output[0]\n",
    "            tool_return = self.agent_executor._get_tool_return(next_step_action)\n",
    "            if tool_return is not None:\n",
    "                output = await self.agent_executor._areturn(\n",
    "                    tool_return, self.intermediate_steps, run_manager=run_manager\n",
    "                )\n",
    "                if self.run_manager:\n",
    "                    await self.run_manager.on_chain_end(output)\n",
    "                self.final_outputs = output\n",
    "                return self.final_outputs\n",
    "\n",
    "        output = {\"intermediate_steps\": self.intermediate_steps}\n",
    "        return output\n",
    "    \n",
    "    def _stop(self) -> None:\n",
    "        output = self.agent_executor.agent.return_stopped_response(\n",
    "            self.agent_executor.early_stopping_method,\n",
    "            self.intermediate_steps,\n",
    "            **self.inputs\n",
    "        )\n",
    "        output = self.agent_executor._return(\n",
    "            output, self.intermediate_steps, run_manager=self.run_manager\n",
    "        )\n",
    "        self.raise_stopiteration(output)\n",
    "    \n",
    "    async def _astop(self) -> None:\n",
    "        output = self.agent_executor.agent.return_stopped_response(\n",
    "            self.agent_executor.early_stopping_method,\n",
    "            self.intermediate_steps,\n",
    "            **self.inputs\n",
    "        )\n",
    "        output = await self.agent_executor._areturn(\n",
    "            output, self.intermediate_steps, run_manager=self.run_manager\n",
    "        )\n",
    "        await self.raise_stopasynciteration(output)\n",
    "        \n",
    "    def _call_next(self) -> dict[str, ty.Any]:\n",
    "        \"\"\"\n",
    "        Single iteration analogue of logic in AgentExecutor _call method\n",
    "        \"\"\"\n",
    "        # final output already reached: stopiteration (final output)\n",
    "        if self.final_outputs is not None:\n",
    "            self.raise_stopiteration(self.final_outputs)\n",
    "        # timeout/max iterations: stopiteration (stopped response)\n",
    "        if not self.agent_executor._should_continue(self.iterations, self.time_elapsed):\n",
    "            self._stop()            \n",
    "        next_step_output = self._execute_next_step()\n",
    "        output = self._process_next_step_output(next_step_output, self.run_manager)\n",
    "        self.update_iterations()\n",
    "        return output\n",
    "\n",
    "    async def _acall_next(self) -> dict[str, ty.Any]:\n",
    "        \"\"\"\n",
    "        Single iteration analogue of logic in AgentExecutor _acall method\n",
    "        \"\"\"\n",
    "        # final output already reached: stopiteration (final output)\n",
    "        if self.final_outputs is not None:\n",
    "            await self.raise_stopasynciteration(self.final_outputs)\n",
    "        # timeout/max iterations: stopiteration (stopped response)\n",
    "        if not self.agent_executor._should_continue(self.iterations, self.time_elapsed):\n",
    "            await self._astop()       \n",
    "        next_step_output = await self._execute_next_async_step()\n",
    "        output = await self._aprocess_next_step_output(next_step_output, self.run_manager)\n",
    "        self.update_iterations()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1bb8cddc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Union' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m----> 3\u001b[0m     inputs: \u001b[43mUnion\u001b[49m[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Any],\n\u001b[1;32m      4\u001b[0m     return_only_outputs: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m     callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m      7\u001b[0m     tags: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m     include_run_info: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    REFERENCE IMPLEMENTATION FROM NON-ITERATOR\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    _call should map onto _call_next  \u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# wanna support modifying iterator before using it so it \u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# doesn't have to be reconstructed for trivial changes\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# factor out to begining of iteration\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Union' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "async def acall(\n",
    "    self,\n",
    "    inputs: Union[Dict[str, Any], Any],\n",
    "    return_only_outputs: bool = False,\n",
    "    callbacks: Callbacks = None,\n",
    "    *,\n",
    "    tags: Optional[List[str]] = None,\n",
    "    include_run_info: bool = False,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Run the logic of this chain and add to output if desired.\n",
    "    \"\"\"\n",
    "    inputs = self.prep_inputs(inputs)\n",
    "    callback_manager = AsyncCallbackManager.configure(\n",
    "        callbacks, self.callbacks, self.verbose, tags, self.tags\n",
    "    )\n",
    "    new_arg_supported = inspect.signature(self._acall).parameters.get(\"run_manager\")\n",
    "    run_manager = await callback_manager.on_chain_start(\n",
    "        dumpd(self),\n",
    "        inputs,\n",
    "    )\n",
    "    try:\n",
    "        outputs = (\n",
    "            await self._acall(inputs, run_manager=run_manager)\n",
    "            if new_arg_supported\n",
    "            else await self._acall(inputs)\n",
    "        )\n",
    "    except (KeyboardInterrupt, Exception) as e:\n",
    "        await run_manager.on_chain_error(e)\n",
    "        raise e\n",
    "    await run_manager.on_chain_end(outputs)\n",
    "    final_outputs: Dict[str, Any] = self.prep_outputs(\n",
    "        inputs, outputs, return_only_outputs\n",
    "    )\n",
    "    if include_run_info:\n",
    "        final_outputs[RUN_KEY] = RunInfo(run_id=run_manager.run_id)\n",
    "    return final_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b89cac",
   "metadata": {},
   "source": [
    "in `_(a)next_step`:\n",
    "\n",
    "If `_should_continue` is True AND we haven't timed out (async):\n",
    "\n",
    "When we hit `AgentFinish` OR determine a direct tool return OR `_should_continue` is false (currently in `process_next_step_output`, in `_call` in original) we:\n",
    "1. return `self._return(outputs, step, run_manager=...)`\n",
    "2. This should take us back up to `__next__` (to `__call__` in original) where we:\n",
    "    - `run_manager.on_chain_end(outputs)`\n",
    "    - `final_outputs = self.prep_outputs(inputs, outputs, return_only_outputs)`\n",
    "    - `if include_run_info: final_outputs[RUN_KEY] = RunInfo(...)`\n",
    "    - return `final_outputs`\n",
    "    - (for us: raise `StopIteration(final_outputs)`)\n",
    "    \n",
    "If `_should_continue` is False OR we time out (async)\n",
    "\n",
    "We `return_stopped_response` and then `_return`/`_areturn` the output\n",
    "(`return_stopped_response` is for when we hit max iter or time out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4daed238",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAgentExecutor(AgentExecutor):\n",
    "    def __call__(\n",
    "        self,\n",
    "        inputs: dict[str, str] | ty.Any,\n",
    "        return_only_outputs: bool = False,\n",
    "        callbacks: Callbacks = None,\n",
    "        *,\n",
    "        tags: list[str] | None = None,\n",
    "        include_run_info: bool = False,\n",
    "        iterator: bool = False,\n",
    "        async_: bool = False,\n",
    "    ) -> dict[str, ty.Any]:\n",
    "        if iterator:\n",
    "            return AgentExecutorIterator(\n",
    "                self,\n",
    "                inputs,\n",
    "                callbacks,\n",
    "                tags=tags,\n",
    "                include_run_info=include_run_info,\n",
    "                async_=async_\n",
    "            )    \n",
    "        else:\n",
    "                inputs,\n",
    "                return_only_outputs,\n",
    "                callbacks,\n",
    "                tags=tags,\n",
    "                include_run_info=include_run_info\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fdde76d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.callback_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "75c781b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signature (inputs: Union[dict[str, str], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: list[str] | None = None, include_run_info: bool = False, iterator: bool = False, async_: bool = False) -> dict[str, typing.Any]>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor = MyAgentExecutor.from_agent_and_tools(\n",
    "    agent=chat_engine._agent.agent,\n",
    "    tools=chat_engine._agent.tools,\n",
    "    callback_manager=chat_engine._agent.callback_manager\n",
    ")\n",
    "agent_executor.memory = chat_engine._agent.memory\n",
    "inspect.signature(agent_executor.__call__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d365010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "16057c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__main__:Initialising AgentExecutorIterator\n",
      "DEBUG:__main__:(Re)setting AgentExecutorIterator to fresh state\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 5 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 2855 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "DEBUG:__main__:Processing output of Agent loop step\n",
      "DEBUG:__main__:Updated intermediate_steps with step output\n",
      "DEBUG:__main__:Agent Iterations: 1 (6.30s elapsed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** STEP:\n",
      "{'intermediate_steps': [(AgentAction(tool='Codeine Source Code Search', tool_input='Codeine source code structure', log='```json\\n{\\n    \"action\": \"Codeine Source Code Search\",\\n    \"action_input\": \"Codeine source code structure\"\\n}\\n```'), 'The Codeine source code is structured into multiple files, including presets.py, chatbot.py, utils.py, README.md, and LICENSE. The presets.py file contains a theme for the Gradio frontend, while chatbot.py contains code for building a chat engine. The utils.py file contains various utility functions, including one for converting Markdown to HTML with syntax highlighting. The README.md file provides installation instructions and information about the project, while the LICENSE file outlines the permissions and conditions for using the Codeine source code.')]}\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__main__:Processing output of Agent loop step\n",
      "DEBUG:__main__:Hit AgentFinish: _return -> on_chain_end -> run final output logic\n",
      "DEBUG:__main__:Agent Iterations: 2 (11.13s elapsed)\n",
      "DEBUG:__main__:Chain end: stop iteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** STEP:\n",
      "{'output': 'The Codeine source code is structured into multiple files, including presets.py, chatbot.py, utils.py, README.md, and LICENSE. The presets.py file contains a theme for the Gradio frontend, while chatbot.py contains code for building a chat engine. The utils.py file contains various utility functions, including one for converting Markdown to HTML with syntax highlighting. The README.md file provides installation instructions and information about the project, while the LICENSE file outlines the permissions and conditions for using the Codeine source code.'}\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "inputs = \"Tell me about the structure of the codeine source code\"\n",
    "\n",
    "for step in agent_executor(inputs=inputs, iterator=True):\n",
    "    print(\"*** STEP:\")\n",
    "    print(step)\n",
    "    print(\"***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "278d4917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__main__:Initialising AgentExecutorIterator (async)\n",
      "DEBUG:__main__:(Re)setting AgentExecutorIterator to fresh state\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1362 request_id=bb02e8978fed09d7d3f94795c04fb2f0 response_code=200\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 5 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 2855 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "DEBUG:__main__:Processing output of async Agent loop step\n",
      "DEBUG:__main__:Updated intermediate_steps with step output\n",
      "DEBUG:__main__:Agent Iterations: 1 (8.28s elapsed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** STEP:\n",
      "{'intermediate_steps': [(AgentAction(tool='Codeine Source Code Search', tool_input='Codeine source code structure', log='```json\\n{\\n    \"action\": \"Codeine Source Code Search\",\\n    \"action_input\": \"Codeine source code structure\"\\n}\\n```'), 'The Codeine source code is structured into multiple files, including presets.py, chatbot.py, utils.py, README.md, and LICENSE. The presets.py file contains a theme for the Gradio frontend, while chatbot.py contains code for building a chat engine. The utils.py file contains various utility functions, including one for converting Markdown to HTML with syntax highlighting. The README.md file provides installation instructions and information about the project, while the LICENSE file outlines the permissions and conditions for using the Codeine source code.')]}\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4611 request_id=a9c0e3d568ee2eff5bcb90be646c197e response_code=200\n",
      "DEBUG:__main__:Processing output of async Agent loop step\n",
      "DEBUG:__main__:Hit AgentFinish: _areturn -> on_chain_end -> run final output logic\n",
      "DEBUG:__main__:Agent Iterations: 2 (13.51s elapsed)\n",
      "DEBUG:__main__:Chain end: stop async iteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** STEP:\n",
      "{'output': 'The Codeine source code is structured into multiple files, including presets.py, chatbot.py, utils.py, README.md, and LICENSE. The presets.py file contains a theme for the Gradio frontend, while chatbot.py contains code for building a chat engine. The utils.py file contains various utility functions, including one for converting Markdown to HTML with syntax highlighting. The README.md file provides installation instructions and information about the project, while the LICENSE file outlines the permissions and conditions for using the Codeine source code.'}\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "inputs = \"Tell me about the structure of the codeine source code\"\n",
    "async_mae_iter = agent_executor(inputs=inputs, iterator=True, async_=True)\n",
    "async_mae_iter.inputs = \"Tell me about ze structure of the codeine source code\"\n",
    "async_mae_iter.agent_executor = async_mae_iter.agent_executor\n",
    "async for step in async_mae_iter:\n",
    "    print(\"*** STEP:\")\n",
    "    print(step)\n",
    "    print(\"***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943f8ca3",
   "metadata": {},
   "source": [
    "Two pieces of code on which design/refactor is based:\n",
    "\n",
    "Original AgentExecutor (non-iterator version) for which we want to mimic the logic\n",
    "https://github.com/hwchase17/langchain/blob/2da1aab50b43c63c7a9a9553b7290230c44604bc/langchain/agents/agent.py#L620\n",
    "\n",
    "The inherited `__call__` and `acall` methods from Chain:\n",
    "https://github.com/hwchase17/langchain/blob/22af93d8516a4ecc05e2c814ad5660c0b6427625/langchain/chains/base.py#L126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2629c9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def todo(self):\n",
    "    \"\"\"\n",
    "    INTEGRATE THIS LOGIC (missing from current implementation, need \n",
    "    to figure out how to structure it)\"\"\"\n",
    "    try:\n",
    "        outputs = (\n",
    "            self._call(inputs, run_manager=run_manager)\n",
    "            if new_arg_supported\n",
    "            else self._call(inputs)\n",
    "        )\n",
    "    except (KeyboardInterrupt, Exception) as e:\n",
    "        run_manager.on_chain_error(e)\n",
    "        raise e\n",
    "    run_manager.on_chain_end(outputs)\n",
    "    final_outputs: Dict[str, Any] = self.prep_outputs(\n",
    "        inputs, outputs, return_only_outputs\n",
    "    )\n",
    "    if include_run_info:\n",
    "        final_outputs[RUN_KEY] = RunInfo(run_id=run_manager.run_id)\n",
    "    return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179c9b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9378a5e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82048de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9be7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4e79d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24b3a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f754f4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ecc94c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5802148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2ea227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e08394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cf3b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf7a6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b885ac5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dff329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b3f4c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b987958d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca59aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9bb979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9dd1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6d2d99a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86d6df51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__aiter__',\n",
       " '__anext__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__next__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_anext_step',\n",
       " '_aprocess_next_step_output',\n",
       " '_chain_end_raise_stopasynciteration',\n",
       " '_chain_end_raise_stopiteration',\n",
       " '_next_step',\n",
       " '_process_next_step_output',\n",
       " 'agent_executor',\n",
       " 'async_',\n",
       " 'build_callback_manager',\n",
       " 'callback_manager',\n",
       " 'callbacks',\n",
       " 'color_mapping',\n",
       " 'include_run_info',\n",
       " 'inputs',\n",
       " 'name_to_tool_map',\n",
       " 'reset',\n",
       " 'update_iterations']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(async_mae_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a46d0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc346c92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543e3b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c6ff14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15d90c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb3e659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0569b093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aa48a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d670f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a279c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75769dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0655a82f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266e21bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f87363b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc5a38d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d847b3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce34642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79142d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def __aiter__(self):\n",
    "    # Initialize instance variables for inputs, run_manager, iterations, time_elapsed, and start_time\n",
    "    self.inputs = ...  # Pass the inputs when initializing the AgentExecutor\n",
    "    self.run_manager = ...  # Pass the run_manager when initializing the AgentExecutor\n",
    "    self.iterations = 0\n",
    "    self.time_elapsed = 0.0\n",
    "    self.start_time = time.time()\n",
    "    self.intermediate_steps = []\n",
    "    return self\n",
    "AgentExecutor.__aiter__ = __aiter__\n",
    "\n",
    "\n",
    "async def __anext__(self) -> Dict[str, Any]:\n",
    "    \"\"\"Async iterator for hooking into agent steps\"\"\"\n",
    "    # Initialization should be done in __aiter__ or another method\n",
    "    # and instance variables should be used for inputs, run_manager, iterations, and time_elapsed\n",
    "\n",
    "    # Construct a mapping of tool name to tool for easy lookup\n",
    "    name_to_tool_map = {tool.name: tool for tool in self.tools}\n",
    "    # We construct a mapping from each tool to a color, used for logging.\n",
    "    color_mapping = get_color_mapping(\n",
    "        [tool.name for tool in self.tools], excluded_colors=[\"green\", \"red\"]\n",
    "    )\n",
    "    intermediate_steps: List[Tuple[AgentAction, str]] = []\n",
    "    # Let's start tracking the number of iterations and time elapsed\n",
    "    iterations = 0\n",
    "    time_elapsed = 0.0\n",
    "    start_time = time.time()\n",
    "    # Agent loop\n",
    "    if not self._should_continue(iterations, time_elapsed):\n",
    "        output = self.agent.return_stopped_response(\n",
    "            self.early_stopping_method, self.intermediate_steps, **self.inputs\n",
    "        )\n",
    "        output = await self._areturn(\n",
    "            output, self.intermediate_steps, run_manager=self.run_manager\n",
    "        )\n",
    "        raise StopAsyncIteration(output)\n",
    "\n",
    "    next_step_output = await self._atake_next_step(\n",
    "        name_to_tool_map,\n",
    "        color_mapping,\n",
    "        inputs,\n",
    "        intermediate_steps,\n",
    "        run_manager=run_manager,\n",
    "    )\n",
    "\n",
    "    if isinstance(next_step_output, AgentFinish):\n",
    "        output = await self._areturn(\n",
    "            next_step_output, intermediate_steps, run_manager=run_manager\n",
    "        )\n",
    "        raise StopAsyncIteration(output)\n",
    "\n",
    "    intermediate_steps.extend(next_step_output)\n",
    "    \n",
    "    # Check for tool return\n",
    "    if len(next_step_output) == 1:\n",
    "        next_step_action = next_step_output[0]\n",
    "        tool_return = self._get_tool_return(next_step_action)\n",
    "        if tool_return is not None:\n",
    "            output = await self._areturn(\n",
    "                tool_return, intermediate_steps, run_manager=run_manager\n",
    "            )\n",
    "            raise StopAsyncIteration(output)\n",
    "            \n",
    "    output = {\"intermediate_steps\": intermediate_steps}\n",
    "\n",
    "    iterations += 1\n",
    "    time_elapsed = time.time() - start_time\n",
    "\n",
    "    return output\n",
    "\n",
    "AgentExecutor.__anext__ = __anext__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85fc6990",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def intermediate_steps_generator(\n",
    "    self,\n",
    "    inputs: dict[str, str],\n",
    "    run_manager: ty.Optional[AsyncCallbackManagerForChainRun] = None,\n",
    ") -> ty.AsyncIterator[tuple[AgentAction, str]]:\n",
    "    \"\"\"Generator function that yields intermediate steps (thoughts, actions, and observations).\"\"\"\n",
    "\n",
    "    logger.debug(\"Starting generator\")\n",
    "\n",
    "    name_to_tool_map = {tool.name: tool for tool in self.tools}\n",
    "    color_mapping = get_color_mapping(\n",
    "        [tool.name for tool in self.tools], excluded_colors=[\"green\"]\n",
    "    )\n",
    "    intermediate_steps: List[Tuple[AgentAction, str]] = []\n",
    "    iterations = 0\n",
    "    time_elapsed = 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    async with asyncio_timeout(self.max_execution_time):\n",
    "        try:\n",
    "            while self._should_continue(iterations, time_elapsed):\n",
    "                logger.debug(f\"Iteration {iterations}\")\n",
    "\n",
    "                next_step_output = await self._atake_next_step(\n",
    "                    name_to_tool_map,\n",
    "                    color_mapping,\n",
    "                    inputs,\n",
    "                    intermediate_steps,\n",
    "                    run_manager=run_manager,\n",
    "                )\n",
    "                if isinstance(next_step_output, AgentFinish):\n",
    "                    # Yield the final answer - Do I want to do this here?\n",
    "                    final_answer = next_step_output.return_values[\"output\"]\n",
    "                    yield next_step_output, final_answer\n",
    "                    logger.debug(\"Agent finished\")\n",
    "                    break\n",
    "\n",
    "                intermediate_steps.extend(next_step_output)\n",
    "                if len(next_step_output) == 1:\n",
    "                    next_step_action = next_step_output[0]\n",
    "                    tool_return = self._get_tool_return(next_step_action)\n",
    "                    if tool_return is not None:\n",
    "                        logger.debug(\"Tool returned\")\n",
    "                        break\n",
    "\n",
    "                # Yield the latest intermediate step(s)\n",
    "                for step_output in next_step_output:\n",
    "                    logger.debug(f\"Yielding step: {step_output}\")\n",
    "                    yield step_output\n",
    "\n",
    "                iterations += 1\n",
    "                time_elapsed = time.time() - start_time\n",
    "        except TimeoutError:\n",
    "            logger.debug(\"TimeoutError\")\n",
    "            pass\n",
    "    logger.debug(\"Generator finished\")\n",
    "\n",
    "AgentExecutor.intermediate_steps_generator = intermediate_steps_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c080d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d34f6798",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def _acall(\n",
    "    self,\n",
    "    inputs: dict[str, str],\n",
    "    run_manager: ty.Optional[AsyncCallbackManagerForChainRun] = None,\n",
    ") -> dict[str, str]:\n",
    "    \"\"\"Run text through and get agent response.\"\"\"\n",
    "    intermediate_steps: list[tuple[AgentAction, str]] = []\n",
    "\n",
    "    async for step in self.intermediate_steps_generator(inputs, run_manager):\n",
    "        intermediate_steps.append(step)\n",
    "\n",
    "    output = self.agent.return_stopped(intermediate_steps)\n",
    "    return output\n",
    "\n",
    "AgentExecutor._acall = _acall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6429d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def _atake_next_step(\n",
    "    self,\n",
    "    name_to_tool_map: dict[str, Tool],\n",
    "    color_mapping: dict[str, str],\n",
    "    inputs: dict[str, str],\n",
    "    intermediate_steps: list[tuple[AgentAction, str]],\n",
    "    run_manager: ty.Optional[AsyncCallbackManagerForChainRun] = None,\n",
    ") -> list[tuple[AgentAction, str]] | AgentFinish:\n",
    "    \"\"\"Take a single step in the thought-action-observation loop.\"\"\"\n",
    "\n",
    "    logger.debug(\"Taking next step\")\n",
    "\n",
    "    try:\n",
    "        # Call the LLM to see what to do.\n",
    "        output = await self.agent.aplan(\n",
    "            intermediate_steps,\n",
    "            callbacks=run_manager.get_child() if run_manager else None,\n",
    "            **inputs,\n",
    "        )\n",
    "    except OutputParserException as e:\n",
    "        if isinstance(self.handle_parsing_errors, bool):\n",
    "            raise_error = not self.handle_parsing_errors\n",
    "        else:\n",
    "            raise_error = False\n",
    "        if raise_error:\n",
    "            raise e\n",
    "        text = str(e)\n",
    "        if isinstance(self.handle_parsing_errors, bool):\n",
    "            if e.send_to_llm:\n",
    "                observation = str(e.observation)\n",
    "                text = str(e.llm_output)\n",
    "            else:\n",
    "                observation = \"Invalid or incomplete response\"\n",
    "        elif isinstance(self.handle_parsing_errors, str):\n",
    "            observation = self.handle_parsing_errors\n",
    "        elif callable(self.handle_parsing_errors):\n",
    "            observation = self.handle_parsing_errors(e)\n",
    "        else:\n",
    "            raise ValueError(\"Got unexpected type of `handle_parsing_errors`\")\n",
    "        output = AgentAction(\"_Exception\", observation, text)\n",
    "        if run_manager:\n",
    "            run_manager.on_agent_action(output, color=\"green\")\n",
    "        tool_run_kwargs = self.agent.tool_run_logging_kwargs()\n",
    "        observation = ExceptionTool().run(\n",
    "            output.tool_input,\n",
    "            verbose=self.verbose,\n",
    "            color=None,\n",
    "            callbacks=run_manager.get_child() if run_manager else None,\n",
    "            **tool_run_kwargs,\n",
    "        )\n",
    "        return [(output, observation)]\n",
    "\n",
    "    logger.debug(f\"Agent output: {output}\")\n",
    "\n",
    "    # If the tool chosen is the finishing tool, then we end and return.\n",
    "    if isinstance(output, AgentFinish):\n",
    "        return output\n",
    "    actions: List[AgentAction]\n",
    "    if isinstance(output, AgentAction):\n",
    "        actions = [output]\n",
    "    else:\n",
    "        actions = output\n",
    "\n",
    "    async def _aperform_agent_action(\n",
    "        agent_action: AgentAction,\n",
    "    ) -> tuple[AgentAction, str]:\n",
    "        if run_manager:\n",
    "            await run_manager.on_agent_action(\n",
    "                agent_action, verbose=self.verbose, color=\"green\"\n",
    "            )\n",
    "        # Otherwise we lookup the tool\n",
    "        if agent_action.tool in name_to_tool_map:\n",
    "            tool = name_to_tool_map[agent_action.tool]\n",
    "            return_direct = tool.return_direct\n",
    "            color = color_mapping[agent_action.tool]\n",
    "            tool_run_kwargs = self.agent.tool_run_logging_kwargs()\n",
    "            if return_direct:\n",
    "                tool_run_kwargs[\"llm_prefix\"] = \"\"\n",
    "            # We then call the tool on the tool input to get an observation\n",
    "            observation = await tool.arun(\n",
    "                agent_action.tool_input,\n",
    "                verbose=self.verbose,\n",
    "                color=color,\n",
    "                callbacks=run_manager.get_child() if run_manager else None,\n",
    "                **tool_run_kwargs,\n",
    "            )\n",
    "        else:\n",
    "            tool_run_kwargs = self.agent.tool_run_logging_kwargs()\n",
    "            observation = await InvalidTool().arun(\n",
    "                agent_action.tool,\n",
    "                verbose=self.verbose,\n",
    "                color=None,\n",
    "                callbacks=run_manager.get_child() if run_manager else None,\n",
    "                **tool_run_kwargs,\n",
    "            )\n",
    "        return agent_action, observation\n",
    "\n",
    "    # Use asyncio.gather to run multiple tool.arun() calls concurrently\n",
    "    result = await asyncio.gather(\n",
    "        *[_aperform_agent_action(agent_action) for agent_action in actions]\n",
    "    )\n",
    "\n",
    "    return list(result)\n",
    "\n",
    "\n",
    "AgentExecutor._atake_next_step = _atake_next_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba6c6481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d7e2ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signature (inputs: Union[dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: list[str] | None = None, include_run_info: bool = False, iterator: bool = False, async_: bool = False) -> dict[str, typing.Any]>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9696bac4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CallbackManager' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmae\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhey\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 14\u001b[0m, in \u001b[0;36mMyAgentExecutor.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info, iterator, async_)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m      4\u001b[0m     inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, ty\u001b[38;5;241m.\u001b[39mAny] \u001b[38;5;241m|\u001b[39m ty\u001b[38;5;241m.\u001b[39mAny,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     async_: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, ty\u001b[38;5;241m.\u001b[39mAny]:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m iterator:\n\u001b[0;32m---> 14\u001b[0m         callback_manager \u001b[38;5;241m=\u001b[39m \u001b[43mCallbackManager\u001b[49m\u001b[38;5;241m.\u001b[39mconfigure(\n\u001b[1;32m     15\u001b[0m             callbacks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, tags, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[1;32m     16\u001b[0m         )\n\u001b[1;32m     17\u001b[0m         run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m     18\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m     19\u001b[0m             inputs,\n\u001b[1;32m     20\u001b[0m         )\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m AgentExecutorIterator(\u001b[38;5;28mself\u001b[39m, inputs, callbacks, async_\u001b[38;5;241m=\u001b[39masync_)    \n",
      "\u001b[0;31mNameError\u001b[0m: name 'CallbackManager' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9960daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_engine._agent.callback_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e6132ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Config',\n",
       " '__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__class_vars__',\n",
       " '__config__',\n",
       " '__custom_root_type__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__exclude_fields__',\n",
       " '__fields__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_validators__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__include_fields__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__json_encoder__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__post_root_validators__',\n",
       " '__pre_root_validators__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__schema_cache__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__signature__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__try_update_forward_refs__',\n",
       " '__validators__',\n",
       " '_abc_impl',\n",
       " '_acall',\n",
       " '_areturn',\n",
       " '_atake_next_step',\n",
       " '_calculate_keys',\n",
       " '_call',\n",
       " '_chain_type',\n",
       " '_copy_and_set_values',\n",
       " '_decompose_class',\n",
       " '_enforce_dict_if_root',\n",
       " '_get_tool_return',\n",
       " '_get_value',\n",
       " '_init_private_attributes',\n",
       " '_iter',\n",
       " '_return',\n",
       " '_should_continue',\n",
       " '_take_next_step',\n",
       " '_validate_inputs',\n",
       " '_validate_outputs',\n",
       " 'acall',\n",
       " 'agent',\n",
       " 'apply',\n",
       " 'arun',\n",
       " 'callback_manager',\n",
       " 'callbacks',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'dict',\n",
       " 'early_stopping_method',\n",
       " 'from_agent_and_tools',\n",
       " 'from_orm',\n",
       " 'handle_parsing_errors',\n",
       " 'input_keys',\n",
       " 'intermediate_steps_generator',\n",
       " 'json',\n",
       " 'lc_attributes',\n",
       " 'lc_kwargs',\n",
       " 'lc_namespace',\n",
       " 'lc_secrets',\n",
       " 'lc_serializable',\n",
       " 'lookup_tool',\n",
       " 'max_execution_time',\n",
       " 'max_iterations',\n",
       " 'memory',\n",
       " 'output_keys',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'prep_inputs',\n",
       " 'prep_outputs',\n",
       " 'raise_deprecation',\n",
       " 'return_intermediate_steps',\n",
       " 'run',\n",
       " 'save',\n",
       " 'save_agent',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'set_verbose',\n",
       " 'tags',\n",
       " 'to_json',\n",
       " 'to_json_not_implemented',\n",
       " 'tools',\n",
       " 'update_forward_refs',\n",
       " 'validate',\n",
       " 'validate_return_direct_tool',\n",
       " 'validate_tools',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(chat_engine._agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07ac1a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_engine._agent.return_intermediate_steps = True\n",
    "chat_engine._agent.verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e648767",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Chain.__call__() missing 1 required positional argument: 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mchat_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Chain.__call__() missing 1 required positional argument: 'inputs'"
     ]
    }
   ],
   "source": [
    "chat_engine._agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cc8656c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1362 request_id=08c2551c8e6d35c00324fb017c8f328d response_code=200\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 4 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 4427 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "INFO:root:==========================================\n",
      "INFO:root:Step: 0\n",
      "INFO:root:Action: AgentAction(tool='Codeine Source Code Search', tool_input='TinyViT', log='{\\n    \"action\": \"Codeine Source Code Search\",\\n    \"action_input\": \"TinyViT\"\\n}')\n",
      "INFO:root:Text: TinyViT is a neural network architecture designed for vision tasks, with a focus on being small and efficient. It consists of multiple transformer blocks with different depths, number of heads, and window sizes, and uses a distillation framework to transfer knowledge from larger models to smaller ones. The TinyViT model has 21 million parameters and is designed for tasks such as neural architecture search, tiny transformer design, and model compression projects. The code snippet provided shows the initialization of a TinyViT model with specific parameters such as image size, number of classes, embedding dimensions, and drop rates.\n",
      "INFO:root:==========================================\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4255 request_id=dafbf95ffc0bfe776bcba95a4b91c38d response_code=200\n",
      "INFO:root:==========================================\n",
      "INFO:root:Step: 1\n",
      "INFO:root:Action: AgentFinish(return_values={'output': 'TinyViT is a small and efficient neural network architecture designed for vision tasks. It consists of multiple transformer blocks with different depths, number of heads, and window sizes, and uses a distillation framework to transfer knowledge from larger models to smaller ones. The TinyViT model has 21 million parameters and is designed for tasks such as neural architecture search, tiny transformer design, and model compression projects.'}, log='{\\n    \"action\": \"Final Answer\",\\n    \"action_input\": \"TinyViT is a small and efficient neural network architecture designed for vision tasks. It consists of multiple transformer blocks with different depths, number of heads, and window sizes, and uses a distillation framework to transfer knowledge from larger models to smaller ones. The TinyViT model has 21 million parameters and is designed for tasks such as neural architecture search, tiny transformer design, and model compression projects.\"\\n}')\n",
      "INFO:root:Text: TinyViT is a small and efficient neural network architecture designed for vision tasks. It consists of multiple transformer blocks with different depths, number of heads, and window sizes, and uses a distillation framework to transfer knowledge from larger models to smaller ones. The TinyViT model has 21 million parameters and is designed for tasks such as neural architecture search, tiny transformer design, and model compression projects.\n",
      "INFO:root:==========================================\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"input\": \"How does TinyViT work?\",\n",
    "    \"chat_history\" : []\n",
    "}\n",
    "\n",
    "async for ix, step in aioitertools.enumerate(chat_engine._agent.intermediate_steps_generator(\n",
    "    inputs,\n",
    ")):\n",
    "    logging.info(\"==========================================\")\n",
    "    logging.info(f\"Step: {ix}\")\n",
    "    if isinstance(step, str): # agent is finished\n",
    "        text = step\n",
    "    else: # agent has a tool to use\n",
    "        action, text = step\n",
    "        logging.info(f\"Action: {action}\")\n",
    "    logging.info(f\"Text: {text}\")\n",
    "    logging.info(\"==========================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6132b3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Training TinyViT, a smaller version of the Vision Transformer (ViT) model, involves a similar process to training the original ViT. The main steps include: 1. Preparing a dataset of images and their corresponding labels. 2. Initializing the TinyViT model with a smaller architecture compared to the original ViT. 3. Feeding the images through the model and computing the loss based on the model's predictions and the true labels. 4. Updating the model's weights using an optimization algorithm, such as Adam or SGD, to minimize the loss. 5. Repeating steps 3 and 4 for multiple epochs until the model converges or reaches a satisfactory performance level. The primary difference between TinyViT and the original ViT is the model's size, which makes TinyViT more efficient and faster to train, while still maintaining competitive performance on various computer vision tasks.\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ec8717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
