{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2a9bcc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import inspect\n",
    "import typing as ty\n",
    "from functools import wraps\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import aioitertools\n",
    "from langchain.input import get_color_mapping\n",
    "from langchain.agents import AgentExecutor, Tool\n",
    "from langchain.agents.agent import AgentAction, AgentFinish\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForChainRun, Callbacks, CallbackManager, AsyncCallbackManager\n",
    ")\n",
    "from langchain.utilities.asyncio import asyncio_timeout\n",
    "from langchain.load.dump import dumpd\n",
    "from langchain.schema import RUN_KEY, RunInfo\n",
    "sys.path.insert(0, \"..\")\n",
    "from codeine.chatbot import build_chat_engine, service_context\n",
    "\n",
    "level = logging.DEBUG\n",
    "#level = logging.INFO\n",
    "logging.basicConfig(level=level)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(level)\n",
    "\n",
    "chat_engine = build_chat_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d7ca3661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_callback_manager_on_set(\n",
    "    setter_method: ty.Callable[..., None]\n",
    ") -> ty.Callable[..., None]:\n",
    "    \"\"\"Decorator to force setters to rebuild callback mgr\"\"\"\n",
    "    @wraps(setter_method)\n",
    "    def wrapper(self: ty.Any, *args: ty.Any, **kwargs: ty.Any) -> None:\n",
    "        setter_method(self, *args, **kwargs)\n",
    "        self.build_callback_manager()\n",
    "    return wrapper\n",
    "\n",
    "class AgentExecutorIterator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        agent_executor: AgentExecutor,\n",
    "        inputs: dict[str, str] | str,\n",
    "        callbacks: Callbacks = None,\n",
    "        *,\n",
    "        tags: list[str] | None = None,\n",
    "        include_run_info: bool = False,\n",
    "        async_: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the AgentExecutorIterator with the given AgentExecutor, \n",
    "        inputs, and optional callbacks.\n",
    "        \"\"\"\n",
    "        self._agent_executor = agent_executor\n",
    "        self.inputs = inputs\n",
    "        self.async_ = async_\n",
    "        # build callback manager on tags setter\n",
    "        self._callbacks = callbacks\n",
    "        self.tags = tags \n",
    "        self.include_run_info = include_run_info\n",
    "        self.run_manager = None\n",
    "    \n",
    "    @property\n",
    "    def inputs(self) -> dict[str, str]:\n",
    "        return self._inputs\n",
    "    \n",
    "    @inputs.setter\n",
    "    def inputs(self, inputs: dict[str, str] | str) -> None:\n",
    "        self._inputs = self.agent_executor.prep_inputs(inputs)\n",
    "    \n",
    "    @property\n",
    "    def callbacks(self):\n",
    "        return self._callbacks\n",
    "    \n",
    "    @property\n",
    "    def tags(self):\n",
    "        return self._tags\n",
    "    \n",
    "    @property\n",
    "    def agent_executor(self):\n",
    "        return self._agent_executor\n",
    "    \n",
    "    @callbacks.setter\n",
    "    @rebuild_callback_manager_on_set\n",
    "    def callbacks(self, callbacks: Callbacks) -> None:\n",
    "        \"\"\"When callbacks are changed after __init__, rebuild callback mgr\"\"\"\n",
    "        self._callbacks = callbacks\n",
    "    \n",
    "    @tags.setter\n",
    "    @rebuild_callback_manager_on_set\n",
    "    def tags(self, tags: list[str] | None) -> None:\n",
    "        \"\"\"When tags are changed after __init__, rebuild callback mgr\"\"\"\n",
    "        self._tags = tags\n",
    "    \n",
    "    @agent_executor.setter\n",
    "    @rebuild_callback_manager_on_set\n",
    "    def agent_executor(self, agent_executor: AgentExecutor) -> None:\n",
    "        self._agent_executor = agent_executor\n",
    "        # force re-prep inputs incase agent_executor's prep_inputs fn changed\n",
    "        self.inputs = self.inputs \n",
    "        \n",
    "    @property\n",
    "    def callback_manager(self) -> AsyncCallbackManager | CallbackManager:\n",
    "        return self._callback_manager\n",
    "    \n",
    "    def build_callback_manager(self) -> None:\n",
    "        \"\"\"\n",
    "        Create and configure the callback manager based on the current callbacks and tags.\n",
    "        \"\"\"\n",
    "        CallbackMgr = AsyncCallbackManager if self.async_ else CallbackManager\n",
    "        self._callback_manager = CallbackMgr.configure(\n",
    "            self.callbacks,\n",
    "            self.agent_executor.callbacks,\n",
    "            self.agent_executor.verbose,\n",
    "            self.tags,\n",
    "            self.agent_executor.tags\n",
    "        )        \n",
    "\n",
    "    @property\n",
    "    def name_to_tool_map(self):\n",
    "        return {tool.name: tool for tool in self.agent_executor.tools}\n",
    "    \n",
    "    @property\n",
    "    def color_mapping(self):\n",
    "        return get_color_mapping(\n",
    "            [tool.name for tool in self.agent_executor.tools],\n",
    "            excluded_colors=[\"green\", \"red\"]\n",
    "        )\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reset the iterator to its initial state, clearing intermediate steps, iterations, and time elapsed.\n",
    "        \"\"\"\n",
    "        logger.debug(f\"(Re)setting AgentExecutorIterator to fresh state\")\n",
    "        self.intermediate_steps: list[tuple[AgentAction, str]] = []\n",
    "        self.iterations = 0\n",
    "        # maybe better to start these on the first __anext__ call?\n",
    "        self.time_elapsed = 0.0\n",
    "        self.start_time = time.time()\n",
    "        self._final_outputs = None\n",
    "        \n",
    "    def update_iterations(self):\n",
    "        \"\"\"\n",
    "        Increment the number of iterations and update the time elapsed.\n",
    "        \"\"\"\n",
    "        self.iterations += 1\n",
    "        self.time_elapsed = time.time() - self.start_time\n",
    "        logger.debug(f\"Agent Iterations: {self.iterations} ({self.time_elapsed:.2f}s elapsed)\")\n",
    "\n",
    "    def raise_stopiteration(self, output: ty.Any):\n",
    "        \"\"\"\n",
    "        Raise a StopIteration exception with the given output.\n",
    "        \"\"\"\n",
    "        logger.debug(\"Chain end: stop iteration\")\n",
    "        raise StopIteration(output)\n",
    "    \n",
    "    async def raise_stopasynciteration(self, output: ty.Any):\n",
    "        \"\"\"\n",
    "        Raise a StopAsyncIteration exception with the given output.\n",
    "        Close the timeout context manager.\n",
    "        \"\"\"\n",
    "        logger.debug(\"Chain end: stop async iteration\")\n",
    "        if self.timeout_manager is not None:\n",
    "            await self.timeout_manager.__aexit__(None, None, None)\n",
    "        raise StopAsyncIteration(output)\n",
    "    \n",
    "    @property\n",
    "    def final_outputs(self):\n",
    "        return self._final_outputs\n",
    "    \n",
    "    @final_outputs.setter\n",
    "    def final_outputs(self, outputs):\n",
    "        # have access to intermediate steps by design in iterator,\n",
    "        # so return only outputs may as well always be true.\n",
    "        final_outputs: dict[str, ty.Any] = self.agent_executor.prep_outputs(\n",
    "            self.inputs, outputs, return_only_outputs=True\n",
    "        )\n",
    "        if self.include_run_info and self.run_manager is not None:\n",
    "            logger.debug(\"Assign run key\")\n",
    "            final_outputs[RUN_KEY] = RunInfo(run_id=self.run_manager.run_id)\n",
    "        self._final_outputs = final_outputs\n",
    "    \n",
    "    def __iter__(self):\n",
    "        logger.debug(\"Initialising AgentExecutorIterator\")\n",
    "        self.reset()\n",
    "        self.run_manager = self.callback_manager.on_chain_start(\n",
    "            dumpd(self.agent_executor),\n",
    "            self.inputs,\n",
    "        )\n",
    "        return self\n",
    "    \n",
    "    def __aiter__(self):\n",
    "        \"\"\"\n",
    "        N.B. __aiter__ must be a normal method, so need to initialise async run manager \n",
    "        on first __anext__ call where we can await it\n",
    "        \"\"\"\n",
    "        logger.debug(\"Initialising AgentExecutorIterator (async)\")\n",
    "        self.reset()\n",
    "        if self.agent_executor.max_execution_time:\n",
    "            self.timeout_manager = asyncio_timeout(self.agent_executor.max_execution_time)\n",
    "        else:\n",
    "            self.timeout_manager = None\n",
    "        return self\n",
    "\n",
    "    def _on_first_step(self) -> None:\n",
    "        \"\"\"\n",
    "        Perform any necessary setup for the first step of the synchronous iterator.\n",
    "        \"\"\"\n",
    "        pass\n",
    "            \n",
    "    async def _on_first_async_step(self) -> None:\n",
    "        \"\"\"\n",
    "        Perform any necessary setup for the first step of the asynchronous iterator.\n",
    "        \"\"\"\n",
    "        # on first step, need to await callback manager and start async timeout ctxmgr\n",
    "        if not self.iterations:\n",
    "            self.run_manager = await self.callback_manager.on_chain_start(\n",
    "                dumpd(self.agent_executor),\n",
    "                self.inputs,\n",
    "            )\n",
    "            if self.timeout_manager:\n",
    "                await self.timeout_manager.__aenter__()\n",
    "    \n",
    "    def __next__(self) -> dict[str, ty.Any]:\n",
    "        \"\"\"\n",
    "        AgentExecutor               AgentExecutorIterator\n",
    "        __call__                    (__iter__ ->) __next__\n",
    "            _call              <=>      _call_next\n",
    "                _take_next_step             _take_next_step   \n",
    "        \"\"\"\n",
    "        # first step\n",
    "        if not self.iterations:\n",
    "            self._on_first_step()\n",
    "        # N.B. timeout taken care of by \"_should_continue\" in sync case\n",
    "        try:\n",
    "            return self._call_next()\n",
    "        except (KeyboardInterrupt, Exception) as e:\n",
    "            self.run_manager.on_chain_error(e)\n",
    "            raise\n",
    "            \n",
    "    async def __anext__(self) -> dict[str, ty.Any]:\n",
    "        \"\"\"\n",
    "        AgentExecutor               AgentExecutorIterator\n",
    "        acall                       (__aiter__ ->) __anext__\n",
    "            _acall              <=>     _acall_next\n",
    "                _atake_next_step            _atake_next_step   \n",
    "        \"\"\"\n",
    "        if not self.iterations:\n",
    "            await self._on_first_async_step()\n",
    "        try:\n",
    "            return await self._acall_next()\n",
    "        except TimeoutError:\n",
    "            await self._astop()\n",
    "        except (KeyboardInterrupt, Exception) as e:\n",
    "            await self.run_manager.on_chain_error(e)\n",
    "            raise\n",
    "        \n",
    "    def _execute_next_step(self):\n",
    "        \"\"\"\n",
    "        Execute the next step in the chain using the AgentExecutor's _take_next_step method.\n",
    "        \"\"\"\n",
    "        return self.agent_executor._take_next_step(\n",
    "            self.name_to_tool_map,\n",
    "            self.color_mapping,\n",
    "            self.inputs,\n",
    "            self.intermediate_steps,\n",
    "            run_manager=self.run_manager,\n",
    "        )\n",
    "\n",
    "    async def _execute_next_async_step(self):\n",
    "        \"\"\"\n",
    "        Execute the next step in the chain using the AgentExecutor's _atake_next_step method.\n",
    "        \"\"\"\n",
    "        return await self.agent_executor._atake_next_step(\n",
    "            self.name_to_tool_map,\n",
    "            self.color_mapping,\n",
    "            self.inputs,\n",
    "            self.intermediate_steps,\n",
    "            run_manager=self.run_manager,\n",
    "        )\n",
    "\n",
    "    def _process_next_step_output(self, next_step_output, run_manager):\n",
    "        \"\"\"\n",
    "        Process the output of the next step, handling AgentFinish and tool return cases.\n",
    "        \"\"\"\n",
    "        logger.debug(\"Processing output of Agent loop step\")\n",
    "        if isinstance(next_step_output, AgentFinish):\n",
    "            logger.debug(f\"Hit AgentFinish: _return -> on_chain_end -> run final output logic\")\n",
    "            output = self.agent_executor._return(\n",
    "                next_step_output, self.intermediate_steps, run_manager=run_manager\n",
    "            )\n",
    "            if self.run_manager:\n",
    "                self.run_manager.on_chain_end(output)\n",
    "            self.final_outputs = output\n",
    "            return self.final_outputs\n",
    "\n",
    "        self.intermediate_steps.extend(next_step_output)\n",
    "        logger.debug(\"Updated intermediate_steps with step output\")\n",
    "\n",
    "        # Check for tool return\n",
    "        if len(next_step_output) == 1:\n",
    "            next_step_action = next_step_output[0]\n",
    "            tool_return = self.agent_executor._get_tool_return(next_step_action)\n",
    "            if tool_return is not None:\n",
    "                output = self.agent_executor._return(\n",
    "                    tool_return, self.intermediate_steps, run_manager=run_manager\n",
    "                )\n",
    "                if self.run_manager:\n",
    "                    self.run_manager.on_chain_end(output)\n",
    "                self.final_outputs = output\n",
    "                return self.final_outputs\n",
    "\n",
    "        output = {\"intermediate_steps\": self.intermediate_steps}\n",
    "        return output\n",
    "\n",
    "    async def _aprocess_next_step_output(self, next_step_output, run_manager):\n",
    "        \"\"\"\n",
    "        Process the output of the next async step, handling AgentFinish and tool return cases.\n",
    "        \"\"\"\n",
    "        logger.debug(\"Processing output of async Agent loop step\")\n",
    "        if isinstance(next_step_output, AgentFinish):\n",
    "            logger.debug(f\"Hit AgentFinish: _areturn -> on_chain_end -> run final output logic\")\n",
    "            output = await self.agent_executor._areturn(\n",
    "                next_step_output, self.intermediate_steps, run_manager=run_manager\n",
    "            )\n",
    "            if self.run_manager:\n",
    "                await self.run_manager.on_chain_end(output)\n",
    "            self.final_outputs = output\n",
    "            return self.final_outputs\n",
    "\n",
    "        self.intermediate_steps.extend(next_step_output)\n",
    "        logger.debug(\"Updated intermediate_steps with step output\")\n",
    "\n",
    "        # Check for tool return\n",
    "        if len(next_step_output) == 1:\n",
    "            next_step_action = next_step_output[0]\n",
    "            tool_return = self.agent_executor._get_tool_return(next_step_action)\n",
    "            if tool_return is not None:\n",
    "                output = await self.agent_executor._areturn(\n",
    "                    tool_return, self.intermediate_steps, run_manager=run_manager\n",
    "                )\n",
    "                if self.run_manager:\n",
    "                    await self.run_manager.on_chain_end(output)\n",
    "                self.final_outputs = output\n",
    "                return self.final_outputs\n",
    "\n",
    "        output = {\"intermediate_steps\": self.intermediate_steps}\n",
    "        return output\n",
    "    \n",
    "    def _stop(self) -> None:\n",
    "        \"\"\"\n",
    "        Stop the iterator and raise a StopIteration exception with the stopped response.\n",
    "        \"\"\"\n",
    "        output = self.agent_executor.agent.return_stopped_response(\n",
    "            self.agent_executor.early_stopping_method,\n",
    "            self.intermediate_steps,\n",
    "            **self.inputs\n",
    "        )\n",
    "        output = self.agent_executor._return(\n",
    "            output, self.intermediate_steps, run_manager=self.run_manager\n",
    "        )\n",
    "        self.raise_stopiteration(output)\n",
    "    \n",
    "    async def _astop(self) -> None:\n",
    "        \"\"\"\n",
    "        Stop the async iterator and raise a StopAsyncIteration exception with \n",
    "        the stopped response.\n",
    "        \"\"\"\n",
    "        output = self.agent_executor.agent.return_stopped_response(\n",
    "            self.agent_executor.early_stopping_method,\n",
    "            self.intermediate_steps,\n",
    "            **self.inputs\n",
    "        )\n",
    "        output = await self.agent_executor._areturn(\n",
    "            output, self.intermediate_steps, run_manager=self.run_manager\n",
    "        )\n",
    "        await self.raise_stopasynciteration(output)\n",
    "        \n",
    "    def _call_next(self) -> dict[str, ty.Any]:\n",
    "        \"\"\"\n",
    "        Perform a single iteration of the synchronous AgentExecutorIterator.\n",
    "        \"\"\"\n",
    "        # final output already reached: stopiteration (final output)\n",
    "        if self.final_outputs is not None:\n",
    "            self.raise_stopiteration(self.final_outputs)\n",
    "        # timeout/max iterations: stopiteration (stopped response)\n",
    "        if not self.agent_executor._should_continue(self.iterations, self.time_elapsed):\n",
    "            self._stop()            \n",
    "        next_step_output = self._execute_next_step()\n",
    "        output = self._process_next_step_output(next_step_output, self.run_manager)\n",
    "        self.update_iterations()\n",
    "        return output\n",
    "\n",
    "    async def _acall_next(self) -> dict[str, ty.Any]:\n",
    "        \"\"\"\n",
    "        Perform a single iteration of the asynchronous AgentExecutorIterator.\n",
    "        \"\"\"\n",
    "        # final output already reached: stopiteration (final output)\n",
    "        if self.final_outputs is not None:\n",
    "            await self.raise_stopasynciteration(self.final_outputs)\n",
    "        # timeout/max iterations: stopiteration (stopped response)\n",
    "        if not self.agent_executor._should_continue(self.iterations, self.time_elapsed):\n",
    "            await self._astop()       \n",
    "        next_step_output = await self._execute_next_async_step()\n",
    "        output = await self._aprocess_next_step_output(next_step_output, self.run_manager)\n",
    "        self.update_iterations()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ec6f5621",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAgentExecutor(AgentExecutor):\n",
    "    def __call__(\n",
    "        self,\n",
    "        inputs: dict[str, str] | ty.Any,\n",
    "        return_only_outputs: bool = False,\n",
    "        callbacks: Callbacks = None,\n",
    "        *,\n",
    "        tags: list[str] | None = None,\n",
    "        include_run_info: bool = False,\n",
    "        iterator: bool = False,\n",
    "        async_: bool = False,\n",
    "    ) -> dict[str, ty.Any]:\n",
    "        if iterator:\n",
    "            return AgentExecutorIterator(\n",
    "                self,\n",
    "                inputs,\n",
    "                callbacks,\n",
    "                tags=tags,\n",
    "                include_run_info=include_run_info,\n",
    "                async_=async_\n",
    "            )    \n",
    "        else:\n",
    "            return super().__call__(\n",
    "                inputs,\n",
    "                return_only_outputs,\n",
    "                callbacks,\n",
    "                tags=tags,\n",
    "                include_run_info=include_run_info\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2fd9a342",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.callback_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c2e26bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signature (inputs: Union[dict[str, str], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: list[str] | None = None, include_run_info: bool = False, iterator: bool = False, async_: bool = False) -> dict[str, typing.Any]>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor = MyAgentExecutor.from_agent_and_tools(\n",
    "    agent=chat_engine._agent.agent,\n",
    "    tools=chat_engine._agent.tools,\n",
    "    callback_manager=chat_engine._agent.callback_manager\n",
    ")\n",
    "agent_executor.memory = chat_engine._agent.memory\n",
    "inspect.signature(agent_executor.__call__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aecc1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4a8e6836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__main__:Initialising AgentExecutorIterator\n",
      "DEBUG:__main__:(Re)setting AgentExecutorIterator to fresh state\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 5 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 2855 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "DEBUG:__main__:Processing output of Agent loop step\n",
      "DEBUG:__main__:Updated intermediate_steps with step output\n",
      "DEBUG:__main__:Agent Iterations: 1 (6.27s elapsed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** STEP:\n",
      "{'intermediate_steps': [(AgentAction(tool='Codeine Source Code Search', tool_input='Codeine source code structure', log='```json\\n{\\n    \"action\": \"Codeine Source Code Search\",\\n    \"action_input\": \"Codeine source code structure\"\\n}\\n```'), 'The Codeine source code is structured into multiple files, including presets.py, chatbot.py, utils.py, README.md, and LICENSE. The presets.py file contains a theme for the Gradio frontend, while chatbot.py contains code for building a chat engine. The utils.py file contains various utility functions, including one for converting Markdown to HTML with syntax highlighting. The README.md file provides installation instructions and information about the project, while the LICENSE file outlines the permissions and conditions for using the Codeine source code.')]}\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__main__:Processing output of Agent loop step\n",
      "DEBUG:__main__:Hit AgentFinish: _return -> on_chain_end -> run final output logic\n",
      "DEBUG:__main__:Agent Iterations: 2 (10.42s elapsed)\n",
      "DEBUG:__main__:Chain end: stop iteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** STEP:\n",
      "{'output': 'The Codeine source code is structured into multiple files, including presets.py, chatbot.py, utils.py, README.md, and LICENSE. The presets.py file contains a theme for the Gradio frontend, while chatbot.py contains code for building a chat engine. The utils.py file contains various utility functions, including one for converting Markdown to HTML with syntax highlighting. The README.md file provides installation instructions and information about the project, while the LICENSE file outlines the permissions and conditions for using the Codeine source code.'}\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "inputs = \"Tell me about the structure of the codeine source code\"\n",
    "\n",
    "for step in agent_executor(inputs=inputs, iterator=True):\n",
    "    print(\"*** STEP:\")\n",
    "    print(step)\n",
    "    print(\"***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "de3bada7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__main__:Initialising AgentExecutorIterator (async)\n",
      "DEBUG:__main__:(Re)setting AgentExecutorIterator to fresh state\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1346 request_id=c1a286a1fd70fcd75dfb2507dd600199 response_code=200\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 5 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 2855 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "DEBUG:__main__:Processing output of async Agent loop step\n",
      "DEBUG:__main__:Updated intermediate_steps with step output\n",
      "DEBUG:__main__:Agent Iterations: 1 (6.97s elapsed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** STEP:\n",
      "{'intermediate_steps': [(AgentAction(tool='Codeine Source Code Search', tool_input='Codeine source code structure', log='```json\\n{\\n    \"action\": \"Codeine Source Code Search\",\\n    \"action_input\": \"Codeine source code structure\"\\n}\\n```'), 'The Codeine source code is structured into multiple files, including presets.py, chatbot.py, utils.py, README.md, and LICENSE. The presets.py file contains a theme for the Gradio frontend, while chatbot.py contains code for building a chat engine. The utils.py file contains various utility functions, including one for converting Markdown to HTML with syntax highlighting. The README.md file provides installation instructions and information about the project, while the LICENSE file outlines the permissions and conditions for using the Codeine source code.')]}\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3573 request_id=6f33d6c5f85b077c81bde7735001ced3 response_code=200\n",
      "DEBUG:__main__:Processing output of async Agent loop step\n",
      "DEBUG:__main__:Hit AgentFinish: _areturn -> on_chain_end -> run final output logic\n",
      "DEBUG:__main__:Agent Iterations: 2 (14.62s elapsed)\n",
      "DEBUG:__main__:Chain end: stop async iteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** STEP:\n",
      "{'output': 'The Codeine source code is structured into multiple files, including presets.py, chatbot.py, utils.py, README.md, and LICENSE. The presets.py file contains a theme for the Gradio frontend, while chatbot.py contains code for building a chat engine. The utils.py file contains various utility functions, including one for converting Markdown to HTML with syntax highlighting. The README.md file provides installation instructions and information about the project, while the LICENSE file outlines the permissions and conditions for using the Codeine source code.'}\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "inputs = \"Tell me about the structure of the codeine source code\"\n",
    "async_mae_iter = agent_executor(inputs=inputs, iterator=True, async_=True)\n",
    "async_mae_iter.inputs = \"Tell me about ze structure of the codeine source code\"\n",
    "async_mae_iter.agent_executor = async_mae_iter.agent_executor\n",
    "async for step in async_mae_iter:\n",
    "    print(\"*** STEP:\")\n",
    "    print(step)\n",
    "    print(\"***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f32b6",
   "metadata": {},
   "source": [
    "Two pieces of code on which design/refactor is based:\n",
    "\n",
    "Original AgentExecutor (non-iterator version) for which we want to mimic the logic\n",
    "https://github.com/hwchase17/langchain/blob/2da1aab50b43c63c7a9a9553b7290230c44604bc/langchain/agents/agent.py#L620\n",
    "\n",
    "The inherited `__call__` and `acall` methods from Chain:\n",
    "https://github.com/hwchase17/langchain/blob/22af93d8516a4ecc05e2c814ad5660c0b6427625/langchain/chains/base.py#L126"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
