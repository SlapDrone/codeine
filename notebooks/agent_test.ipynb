{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71adf7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import inspect\n",
    "import typing as ty\n",
    "\n",
    "import aioitertools\n",
    "from langchain.input import get_color_mapping\n",
    "from langchain.agents import AgentExecutor, Tool\n",
    "from langchain.agents.agent import AgentAction, AgentFinish\n",
    "from langchain.callbacks.manager import AsyncCallbackManagerForChainRun\n",
    "from langchain.utilities.asyncio import asyncio_timeout\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "from codeine.chatbot import build_chat_engine, service_context\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "chat_engine = build_chat_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128bb0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def __aiter__(self):\n",
    "    # Initialize instance variables for inputs, run_manager, iterations, time_elapsed, and start_time\n",
    "    self.inputs = ...  # Pass the inputs when initializing the AgentExecutor\n",
    "    self.run_manager = ...  # Pass the run_manager when initializing the AgentExecutor\n",
    "    self.iterations = 0\n",
    "    self.time_elapsed = 0.0\n",
    "    self.start_time = time.time()\n",
    "    self.intermediate_steps = []\n",
    "    return self\n",
    "AgentExecutor.__aiter__ = __aiter__\n",
    "\n",
    "\n",
    "async def __anext__(self) -> Dict[str, Any]:\n",
    "    \"\"\"Async iterator for hooking into agent steps\"\"\"\n",
    "    # Initialization should be done in __aiter__ or another method\n",
    "    # and instance variables should be used for inputs, run_manager, iterations, and time_elapsed\n",
    "\n",
    "    # Construct a mapping of tool name to tool for easy lookup\n",
    "    name_to_tool_map = {tool.name: tool for tool in self.tools}\n",
    "    # We construct a mapping from each tool to a color, used for logging.\n",
    "    color_mapping = get_color_mapping(\n",
    "        [tool.name for tool in self.tools], excluded_colors=[\"green\", \"red\"]\n",
    "    )\n",
    "    intermediate_steps: List[Tuple[AgentAction, str]] = []\n",
    "    # Let's start tracking the number of iterations and time elapsed\n",
    "    iterations = 0\n",
    "    time_elapsed = 0.0\n",
    "    start_time = time.time()\n",
    "    # Agent loop\n",
    "    if not self._should_continue(iterations, time_elapsed):\n",
    "        output = self.agent.return_stopped_response(\n",
    "            self.early_stopping_method, self.intermediate_steps, **self.inputs\n",
    "        )\n",
    "        output = await self._areturn(\n",
    "            output, self.intermediate_steps, run_manager=self.run_manager\n",
    "        )\n",
    "        raise StopAsyncIteration(output)\n",
    "\n",
    "    next_step_output = await self._atake_next_step(\n",
    "        name_to_tool_map,\n",
    "        color_mapping,\n",
    "        inputs,\n",
    "        intermediate_steps,\n",
    "        run_manager=run_manager,\n",
    "    )\n",
    "\n",
    "    if isinstance(next_step_output, AgentFinish):\n",
    "        output = await self._areturn(\n",
    "            next_step_output, intermediate_steps, run_manager=run_manager\n",
    "        )\n",
    "        raise StopAsyncIteration(output)\n",
    "\n",
    "    intermediate_steps.extend(next_step_output)\n",
    "    \n",
    "    # Check for tool return\n",
    "    if len(next_step_output) == 1:\n",
    "        next_step_action = next_step_output[0]\n",
    "        tool_return = self._get_tool_return(next_step_action)\n",
    "        if tool_return is not None:\n",
    "            output = await self._areturn(\n",
    "                tool_return, intermediate_steps, run_manager=run_manager\n",
    "            )\n",
    "            raise StopAsyncIteration(output)\n",
    "            \n",
    "    output = {\"intermediate_steps\": intermediate_steps}\n",
    "\n",
    "    iterations += 1\n",
    "    time_elapsed = time.time() - start_time\n",
    "\n",
    "    return output\n",
    "\n",
    "AgentExecutor.__anext__ = __anext__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e1ae32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def intermediate_steps_generator(\n",
    "    self,\n",
    "    inputs: dict[str, str],\n",
    "    run_manager: ty.Optional[AsyncCallbackManagerForChainRun] = None,\n",
    ") -> ty.AsyncIterator[tuple[AgentAction, str]]:\n",
    "    \"\"\"Generator function that yields intermediate steps (thoughts, actions, and observations).\"\"\"\n",
    "\n",
    "    logger.debug(\"Starting generator\")\n",
    "\n",
    "    name_to_tool_map = {tool.name: tool for tool in self.tools}\n",
    "    color_mapping = get_color_mapping(\n",
    "        [tool.name for tool in self.tools], excluded_colors=[\"green\"]\n",
    "    )\n",
    "    intermediate_steps: List[Tuple[AgentAction, str]] = []\n",
    "    iterations = 0\n",
    "    time_elapsed = 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    async with asyncio_timeout(self.max_execution_time):\n",
    "        try:\n",
    "            while self._should_continue(iterations, time_elapsed):\n",
    "                logger.debug(f\"Iteration {iterations}\")\n",
    "\n",
    "                next_step_output = await self._atake_next_step(\n",
    "                    name_to_tool_map,\n",
    "                    color_mapping,\n",
    "                    inputs,\n",
    "                    intermediate_steps,\n",
    "                    run_manager=run_manager,\n",
    "                )\n",
    "                if isinstance(next_step_output, AgentFinish):\n",
    "                    # Yield the final answer - Do I want to do this here?\n",
    "                    final_answer = next_step_output.return_values[\"output\"]\n",
    "                    yield next_step_output, final_answer\n",
    "                    logger.debug(\"Agent finished\")\n",
    "                    break\n",
    "\n",
    "                intermediate_steps.extend(next_step_output)\n",
    "                if len(next_step_output) == 1:\n",
    "                    next_step_action = next_step_output[0]\n",
    "                    tool_return = self._get_tool_return(next_step_action)\n",
    "                    if tool_return is not None:\n",
    "                        logger.debug(\"Tool returned\")\n",
    "                        break\n",
    "\n",
    "                # Yield the latest intermediate step(s)\n",
    "                for step_output in next_step_output:\n",
    "                    logger.debug(f\"Yielding step: {step_output}\")\n",
    "                    yield step_output\n",
    "\n",
    "                iterations += 1\n",
    "                time_elapsed = time.time() - start_time\n",
    "        except TimeoutError:\n",
    "            logger.debug(\"TimeoutError\")\n",
    "            pass\n",
    "    logger.debug(\"Generator finished\")\n",
    "\n",
    "AgentExecutor.intermediate_steps_generator = intermediate_steps_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ef7efd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b487f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def _acall(\n",
    "    self,\n",
    "    inputs: dict[str, str],\n",
    "    run_manager: ty.Optional[AsyncCallbackManagerForChainRun] = None,\n",
    ") -> dict[str, str]:\n",
    "    \"\"\"Run text through and get agent response.\"\"\"\n",
    "    intermediate_steps: list[tuple[AgentAction, str]] = []\n",
    "\n",
    "    async for step in self.intermediate_steps_generator(inputs, run_manager):\n",
    "        intermediate_steps.append(step)\n",
    "\n",
    "    output = self.agent.return_stopped(intermediate_steps)\n",
    "    return output\n",
    "\n",
    "AgentExecutor._acall = _acall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27e40a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def _atake_next_step(\n",
    "    self,\n",
    "    name_to_tool_map: dict[str, Tool],\n",
    "    color_mapping: dict[str, str],\n",
    "    inputs: dict[str, str],\n",
    "    intermediate_steps: list[tuple[AgentAction, str]],\n",
    "    run_manager: ty.Optional[AsyncCallbackManagerForChainRun] = None,\n",
    ") -> list[tuple[AgentAction, str]] | AgentFinish:\n",
    "    \"\"\"Take a single step in the thought-action-observation loop.\"\"\"\n",
    "\n",
    "    logger.debug(\"Taking next step\")\n",
    "\n",
    "    try:\n",
    "        # Call the LLM to see what to do.\n",
    "        output = await self.agent.aplan(\n",
    "            intermediate_steps,\n",
    "            callbacks=run_manager.get_child() if run_manager else None,\n",
    "            **inputs,\n",
    "        )\n",
    "    except OutputParserException as e:\n",
    "        if isinstance(self.handle_parsing_errors, bool):\n",
    "            raise_error = not self.handle_parsing_errors\n",
    "        else:\n",
    "            raise_error = False\n",
    "        if raise_error:\n",
    "            raise e\n",
    "        text = str(e)\n",
    "        if isinstance(self.handle_parsing_errors, bool):\n",
    "            if e.send_to_llm:\n",
    "                observation = str(e.observation)\n",
    "                text = str(e.llm_output)\n",
    "            else:\n",
    "                observation = \"Invalid or incomplete response\"\n",
    "        elif isinstance(self.handle_parsing_errors, str):\n",
    "            observation = self.handle_parsing_errors\n",
    "        elif callable(self.handle_parsing_errors):\n",
    "            observation = self.handle_parsing_errors(e)\n",
    "        else:\n",
    "            raise ValueError(\"Got unexpected type of `handle_parsing_errors`\")\n",
    "        output = AgentAction(\"_Exception\", observation, text)\n",
    "        if run_manager:\n",
    "            run_manager.on_agent_action(output, color=\"green\")\n",
    "        tool_run_kwargs = self.agent.tool_run_logging_kwargs()\n",
    "        observation = ExceptionTool().run(\n",
    "            output.tool_input,\n",
    "            verbose=self.verbose,\n",
    "            color=None,\n",
    "            callbacks=run_manager.get_child() if run_manager else None,\n",
    "            **tool_run_kwargs,\n",
    "        )\n",
    "        return [(output, observation)]\n",
    "\n",
    "    logger.debug(f\"Agent output: {output}\")\n",
    "\n",
    "    # If the tool chosen is the finishing tool, then we end and return.\n",
    "    if isinstance(output, AgentFinish):\n",
    "        return output\n",
    "    actions: List[AgentAction]\n",
    "    if isinstance(output, AgentAction):\n",
    "        actions = [output]\n",
    "    else:\n",
    "        actions = output\n",
    "\n",
    "    async def _aperform_agent_action(\n",
    "        agent_action: AgentAction,\n",
    "    ) -> tuple[AgentAction, str]:\n",
    "        if run_manager:\n",
    "            await run_manager.on_agent_action(\n",
    "                agent_action, verbose=self.verbose, color=\"green\"\n",
    "            )\n",
    "        # Otherwise we lookup the tool\n",
    "        if agent_action.tool in name_to_tool_map:\n",
    "            tool = name_to_tool_map[agent_action.tool]\n",
    "            return_direct = tool.return_direct\n",
    "            color = color_mapping[agent_action.tool]\n",
    "            tool_run_kwargs = self.agent.tool_run_logging_kwargs()\n",
    "            if return_direct:\n",
    "                tool_run_kwargs[\"llm_prefix\"] = \"\"\n",
    "            # We then call the tool on the tool input to get an observation\n",
    "            observation = await tool.arun(\n",
    "                agent_action.tool_input,\n",
    "                verbose=self.verbose,\n",
    "                color=color,\n",
    "                callbacks=run_manager.get_child() if run_manager else None,\n",
    "                **tool_run_kwargs,\n",
    "            )\n",
    "        else:\n",
    "            tool_run_kwargs = self.agent.tool_run_logging_kwargs()\n",
    "            observation = await InvalidTool().arun(\n",
    "                agent_action.tool,\n",
    "                verbose=self.verbose,\n",
    "                color=None,\n",
    "                callbacks=run_manager.get_child() if run_manager else None,\n",
    "                **tool_run_kwargs,\n",
    "            )\n",
    "        return agent_action, observation\n",
    "\n",
    "    # Use asyncio.gather to run multiple tool.arun() calls concurrently\n",
    "    result = await asyncio.gather(\n",
    "        *[_aperform_agent_action(agent_action) for agent_action in actions]\n",
    "    )\n",
    "\n",
    "    return list(result)\n",
    "\n",
    "\n",
    "AgentExecutor._atake_next_step = _atake_next_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f1bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_engine._agent.return_intermediate_steps = True\n",
    "chat_engine._agent.verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09bab4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(verbose=False, callbacks=None, callback_manager=None, tags=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_engine._service_context.llm_predictor.llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d60639f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1362 request_id=08c2551c8e6d35c00324fb017c8f328d response_code=200\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 4 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 4427 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "INFO:root:==========================================\n",
      "INFO:root:Step: 0\n",
      "INFO:root:Action: AgentAction(tool='Codeine Source Code Search', tool_input='TinyViT', log='{\\n    \"action\": \"Codeine Source Code Search\",\\n    \"action_input\": \"TinyViT\"\\n}')\n",
      "INFO:root:Text: TinyViT is a neural network architecture designed for vision tasks, with a focus on being small and efficient. It consists of multiple transformer blocks with different depths, number of heads, and window sizes, and uses a distillation framework to transfer knowledge from larger models to smaller ones. The TinyViT model has 21 million parameters and is designed for tasks such as neural architecture search, tiny transformer design, and model compression projects. The code snippet provided shows the initialization of a TinyViT model with specific parameters such as image size, number of classes, embedding dimensions, and drop rates.\n",
      "INFO:root:==========================================\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4255 request_id=dafbf95ffc0bfe776bcba95a4b91c38d response_code=200\n",
      "INFO:root:==========================================\n",
      "INFO:root:Step: 1\n",
      "INFO:root:Action: AgentFinish(return_values={'output': 'TinyViT is a small and efficient neural network architecture designed for vision tasks. It consists of multiple transformer blocks with different depths, number of heads, and window sizes, and uses a distillation framework to transfer knowledge from larger models to smaller ones. The TinyViT model has 21 million parameters and is designed for tasks such as neural architecture search, tiny transformer design, and model compression projects.'}, log='{\\n    \"action\": \"Final Answer\",\\n    \"action_input\": \"TinyViT is a small and efficient neural network architecture designed for vision tasks. It consists of multiple transformer blocks with different depths, number of heads, and window sizes, and uses a distillation framework to transfer knowledge from larger models to smaller ones. The TinyViT model has 21 million parameters and is designed for tasks such as neural architecture search, tiny transformer design, and model compression projects.\"\\n}')\n",
      "INFO:root:Text: TinyViT is a small and efficient neural network architecture designed for vision tasks. It consists of multiple transformer blocks with different depths, number of heads, and window sizes, and uses a distillation framework to transfer knowledge from larger models to smaller ones. The TinyViT model has 21 million parameters and is designed for tasks such as neural architecture search, tiny transformer design, and model compression projects.\n",
      "INFO:root:==========================================\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"input\": \"How does TinyViT work?\",\n",
    "    \"chat_history\" : []\n",
    "}\n",
    "\n",
    "async for ix, step in aioitertools.enumerate(chat_engine._agent.intermediate_steps_generator(\n",
    "    inputs,\n",
    ")):\n",
    "    logging.info(\"==========================================\")\n",
    "    logging.info(f\"Step: {ix}\")\n",
    "    if isinstance(step, str): # agent is finished\n",
    "        text = step\n",
    "    else: # agent has a tool to use\n",
    "        action, text = step\n",
    "        logging.info(f\"Action: {action}\")\n",
    "    logging.info(f\"Text: {text}\")\n",
    "    logging.info(\"==========================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "415c311a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Training TinyViT, a smaller version of the Vision Transformer (ViT) model, involves a similar process to training the original ViT. The main steps include: 1. Preparing a dataset of images and their corresponding labels. 2. Initializing the TinyViT model with a smaller architecture compared to the original ViT. 3. Feeding the images through the model and computing the loss based on the model's predictions and the true labels. 4. Updating the model's weights using an optimization algorithm, such as Adam or SGD, to minimize the loss. 5. Repeating steps 3 and 4 for multiple epochs until the model converges or reaches a satisfactory performance level. The primary difference between TinyViT and the original ViT is the model's size, which makes TinyViT more efficient and faster to train, while still maintaining competitive performance on various computer vision tasks.\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02b0d72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class AgentExecutor(Chain):\n",
      "    \"\"\"Consists of an agent using tools.\"\"\"\n",
      "\n",
      "    agent: Union[BaseSingleActionAgent, BaseMultiActionAgent]\n",
      "    tools: Sequence[BaseTool]\n",
      "    return_intermediate_steps: bool = False\n",
      "    max_iterations: Optional[int] = 15\n",
      "    max_execution_time: Optional[float] = None\n",
      "    early_stopping_method: str = \"force\"\n",
      "    handle_parsing_errors: Union[\n",
      "        bool, str, Callable[[OutputParserException], str]\n",
      "    ] = False\n",
      "\n",
      "    @classmethod\n",
      "    def from_agent_and_tools(\n",
      "        cls,\n",
      "        agent: Union[BaseSingleActionAgent, BaseMultiActionAgent],\n",
      "        tools: Sequence[BaseTool],\n",
      "        callback_manager: Optional[BaseCallbackManager] = None,\n",
      "        **kwargs: Any,\n",
      "    ) -> AgentExecutor:\n",
      "        \"\"\"Create from agent and tools.\"\"\"\n",
      "        return cls(\n",
      "            agent=agent, tools=tools, callback_manager=callback_manager, **kwargs\n",
      "        )\n",
      "\n",
      "    @root_validator()\n",
      "    def validate_tools(cls, values: Dict) -> Dict:\n",
      "        \"\"\"Validate that tools are compatible with agent.\"\"\"\n",
      "        agent = values[\"agent\"]\n",
      "        tools = values[\"tools\"]\n",
      "        allowed_tools = agent.get_allowed_tools()\n",
      "        if allowed_tools is not None:\n",
      "            if set(allowed_tools) != set([tool.name for tool in tools]):\n",
      "                raise ValueError(\n",
      "                    f\"Allowed tools ({allowed_tools}) different than \"\n",
      "                    f\"provided tools ({[tool.name for tool in tools]})\"\n",
      "                )\n",
      "        return values\n",
      "\n",
      "    @root_validator()\n",
      "    def validate_return_direct_tool(cls, values: Dict) -> Dict:\n",
      "        \"\"\"Validate that tools are compatible with agent.\"\"\"\n",
      "        agent = values[\"agent\"]\n",
      "        tools = values[\"tools\"]\n",
      "        if isinstance(agent, BaseMultiActionAgent):\n",
      "            for tool in tools:\n",
      "                if tool.return_direct:\n",
      "                    raise ValueError(\n",
      "                        \"Tools that have `return_direct=True` are not allowed \"\n",
      "                        \"in multi-action agents\"\n",
      "                    )\n",
      "        return values\n",
      "\n",
      "    def save(self, file_path: Union[Path, str]) -> None:\n",
      "        \"\"\"Raise error - saving not supported for Agent Executors.\"\"\"\n",
      "        raise ValueError(\n",
      "            \"Saving not supported for agent executors. \"\n",
      "            \"If you are trying to save the agent, please use the \"\n",
      "            \"`.save_agent(...)`\"\n",
      "        )\n",
      "\n",
      "    def save_agent(self, file_path: Union[Path, str]) -> None:\n",
      "        \"\"\"Save the underlying agent.\"\"\"\n",
      "        return self.agent.save(file_path)\n",
      "\n",
      "    @property\n",
      "    def input_keys(self) -> List[str]:\n",
      "        \"\"\"Return the input keys.\n",
      "\n",
      "        :meta private:\n",
      "        \"\"\"\n",
      "        return self.agent.input_keys\n",
      "\n",
      "    @property\n",
      "    def output_keys(self) -> List[str]:\n",
      "        \"\"\"Return the singular output key.\n",
      "\n",
      "        :meta private:\n",
      "        \"\"\"\n",
      "        if self.return_intermediate_steps:\n",
      "            return self.agent.return_values + [\"intermediate_steps\"]\n",
      "        else:\n",
      "            return self.agent.return_values\n",
      "\n",
      "    def lookup_tool(self, name: str) -> BaseTool:\n",
      "        \"\"\"Lookup tool by name.\"\"\"\n",
      "        return {tool.name: tool for tool in self.tools}[name]\n",
      "\n",
      "    def _should_continue(self, iterations: int, time_elapsed: float) -> bool:\n",
      "        if self.max_iterations is not None and iterations >= self.max_iterations:\n",
      "            return False\n",
      "        if (\n",
      "            self.max_execution_time is not None\n",
      "            and time_elapsed >= self.max_execution_time\n",
      "        ):\n",
      "            return False\n",
      "\n",
      "        return True\n",
      "\n",
      "    def _return(\n",
      "        self,\n",
      "        output: AgentFinish,\n",
      "        intermediate_steps: list,\n",
      "        run_manager: Optional[CallbackManagerForChainRun] = None,\n",
      "    ) -> Dict[str, Any]:\n",
      "        if run_manager:\n",
      "            run_manager.on_agent_finish(output, color=\"green\", verbose=self.verbose)\n",
      "        final_output = output.return_values\n",
      "        if self.return_intermediate_steps:\n",
      "            final_output[\"intermediate_steps\"] = intermediate_steps\n",
      "        return final_output\n",
      "\n",
      "    async def _areturn(\n",
      "        self,\n",
      "        output: AgentFinish,\n",
      "        intermediate_steps: list,\n",
      "        run_manager: Optional[AsyncCallbackManagerForChainRun] = None,\n",
      "    ) -> Dict[str, Any]:\n",
      "        if run_manager:\n",
      "            await run_manager.on_agent_finish(\n",
      "                output, color=\"green\", verbose=self.verbose\n",
      "            )\n",
      "        final_output = output.return_values\n",
      "        if self.return_intermediate_steps:\n",
      "            final_output[\"intermediate_steps\"] = intermediate_steps\n",
      "        return final_output\n",
      "\n",
      "    def _take_next_step(\n",
      "        self,\n",
      "        name_to_tool_map: Dict[str, BaseTool],\n",
      "        color_mapping: Dict[str, str],\n",
      "        inputs: Dict[str, str],\n",
      "        intermediate_steps: List[Tuple[AgentAction, str]],\n",
      "        run_manager: Optional[CallbackManagerForChainRun] = None,\n",
      "    ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n",
      "        \"\"\"Take a single step in the thought-action-observation loop.\n",
      "\n",
      "        Override this to take control of how the agent makes and acts on choices.\n",
      "        \"\"\"\n",
      "        try:\n",
      "            # Call the LLM to see what to do.\n",
      "            output = self.agent.plan(\n",
      "                intermediate_steps,\n",
      "                callbacks=run_manager.get_child() if run_manager else None,\n",
      "                **inputs,\n",
      "            )\n",
      "        except OutputParserException as e:\n",
      "            if isinstance(self.handle_parsing_errors, bool):\n",
      "                raise_error = not self.handle_parsing_errors\n",
      "            else:\n",
      "                raise_error = False\n",
      "            if raise_error:\n",
      "                raise e\n",
      "            text = str(e)\n",
      "            if isinstance(self.handle_parsing_errors, bool):\n",
      "                if e.send_to_llm:\n",
      "                    observation = str(e.observation)\n",
      "                    text = str(e.llm_output)\n",
      "                else:\n",
      "                    observation = \"Invalid or incomplete response\"\n",
      "            elif isinstance(self.handle_parsing_errors, str):\n",
      "                observation = self.handle_parsing_errors\n",
      "            elif callable(self.handle_parsing_errors):\n",
      "                observation = self.handle_parsing_errors(e)\n",
      "            else:\n",
      "                raise ValueError(\"Got unexpected type of `handle_parsing_errors`\")\n",
      "            output = AgentAction(\"_Exception\", observation, text)\n",
      "            if run_manager:\n",
      "                run_manager.on_agent_action(output, color=\"green\")\n",
      "            tool_run_kwargs = self.agent.tool_run_logging_kwargs()\n",
      "            observation = ExceptionTool().run(\n",
      "                output.tool_input,\n",
      "                verbose=self.verbose,\n",
      "                color=None,\n",
      "                callbacks=run_manager.get_child() if run_manager else None,\n",
      "                **tool_run_kwargs,\n",
      "            )\n",
      "            return [(output, observation)]\n",
      "        # If the tool chosen is the finishing tool, then we end and return.\n",
      "        if isinstance(output, AgentFinish):\n",
      "            return output\n",
      "        actions: List[AgentAction]\n",
      "        if isinstance(output, AgentAction):\n",
      "            actions = [output]\n",
      "        else:\n",
      "            actions = output\n",
      "        result = []\n",
      "        for agent_action in actions:\n",
      "            if run_manager:\n",
      "                run_manager.on_agent_action(agent_action, color=\"green\")\n",
      "            # Otherwise we lookup the tool\n",
      "            if agent_action.tool in name_to_tool_map:\n",
      "                tool = name_to_tool_map[agent_action.tool]\n",
      "                return_direct = tool.return_direct\n",
      "                color = color_mapping[agent_action.tool]\n",
      "                tool_run_kwargs = self.agent.tool_run_logging_kwargs()\n",
      "                if return_direct:\n",
      "                    tool_run_kwargs[\"llm_prefix\"] = \"\"\n",
      "                # We then call the tool on the tool input to get an observation\n",
      "                observation = tool.run(\n",
      "                    agent_action.tool_input,\n",
      "                    verbose=self.verbose,\n",
      "                    color=color,\n",
      "                    callbacks=run_manager.get_child() if run_manager else None,\n",
      "                    **tool_run_kwargs,\n",
      "                )\n",
      "            else:\n",
      "                tool_run_kwargs = self.agent.tool_run_logging_kwargs()\n",
      "                observation = InvalidTool().run(\n",
      "                    agent_action.tool,\n",
      "                    verbose=self.verbose,\n",
      "                    color=None,\n",
      "                    callbacks=run_manager.get_child() if run_manager else None,\n",
      "                    **tool_run_kwargs,\n",
      "                )\n",
      "            result.append((agent_action, observation))\n",
      "        return result\n",
      "\n",
      "    async def _atake_next_step(\n",
      "        self,\n",
      "        name_to_tool_map: Dict[str, BaseTool],\n",
      "        color_mapping: Dict[str, str],\n",
      "        inputs: Dict[str, str],\n",
      "        intermediate_steps: List[Tuple[AgentAction, str]],\n",
      "        run_manager: Optional[AsyncCallbackManagerForChainRun] = None,\n",
      "    ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n",
      "        \"\"\"Take a single step in the thought-action-observation loop.\n",
      "\n",
      "        Override this to take control of how the agent makes and acts on choices.\n",
      "        \"\"\"\n",
      "        try:\n",
      "            # Call the LLM to see what to do.\n",
      "            output = await self.agent.aplan(\n",
      "                intermediate_steps,\n",
      "                callbacks=run_manager.get_child() if run_manager else None,\n",
      "                **inputs,\n",
      "            )\n",
      "        except OutputParserException as e:\n",
      "            if isinstance(self.handle_parsing_errors, bool):\n",
      "                raise_error = not self.handle_parsing_errors\n",
      "            else:\n",
      "                raise_error = False\n",
      "            if raise_error:\n",
      "                raise e\n",
      "            text = str(e)\n",
      "            if isinstance(self.handle_parsing_errors, bool):\n",
      "                if e.send_to_llm:\n",
      "                    observation = str(e.observation)\n",
      "                    text = str(e.llm_output)\n",
      "                else:\n",
      "                    observation = \"Invalid or incomplete response\"\n",
      "            elif isinstance(self.handle_parsing_errors, str):\n",
      "                observation = self.handle_parsing_errors\n",
      "            elif callable(self.handle_parsing_errors):\n",
      "                observation = self.handle_parsing_errors(e)\n",
      "            else:\n",
      "                raise ValueError(\"Got unexpected type of `handle_parsing_errors`\")\n",
      "            output = AgentAction(\"_Exception\", observation, text)\n",
      "            tool_run_kwargs = self.agent.tool_run_logging_kwargs()\n",
      "            observation = await ExceptionTool().arun(\n",
      "                output.tool_input,\n",
      "                verbose=self.verbose,\n",
      "                color=None,\n",
      "                callbacks=run_manager.get_child() if run_manager else None,\n",
      "                **tool_run_kwargs,\n",
      "            )\n",
      "            return [(output, observation)]\n",
      "        # If the tool chosen is the finishing tool, then we end and return.\n",
      "        if isinstance(output, AgentFinish):\n",
      "            return output\n",
      "        actions: List[AgentAction]\n",
      "        if isinstance(output, AgentAction):\n",
      "            actions = [output]\n",
      "        else:\n",
      "            actions = output\n",
      "\n",
      "        async def _aperform_agent_action(\n",
      "            agent_action: AgentAction,\n",
      "        ) -> Tuple[AgentAction, str]:\n",
      "            if run_manager:\n",
      "                await run_manager.on_agent_action(\n",
      "                    agent_action, verbose=self.verbose, color=\"green\"\n",
      "                )\n",
      "            # Otherwise we lookup the tool\n",
      "            if agent_action.tool in name_to_tool_map:\n",
      "                tool = name_to_tool_map[agent_action.tool]\n",
      "                return_direct = tool.return_direct\n",
      "                color = color_mapping[agent_action.tool]\n",
      "                tool_run_kwargs = self.agent.tool_run_logging_kwargs()\n",
      "                if return_direct:\n",
      "                    tool_run_kwargs[\"llm_prefix\"] = \"\"\n",
      "                # We then call the tool on the tool input to get an observation\n",
      "                observation = await tool.arun(\n",
      "                    agent_action.tool_input,\n",
      "                    verbose=self.verbose,\n",
      "                    color=color,\n",
      "                    callbacks=run_manager.get_child() if run_manager else None,\n",
      "                    **tool_run_kwargs,\n",
      "                )\n",
      "            else:\n",
      "                tool_run_kwargs = self.agent.tool_run_logging_kwargs()\n",
      "                observation = await InvalidTool().arun(\n",
      "                    agent_action.tool,\n",
      "                    verbose=self.verbose,\n",
      "                    color=None,\n",
      "                    callbacks=run_manager.get_child() if run_manager else None,\n",
      "                    **tool_run_kwargs,\n",
      "                )\n",
      "            return agent_action, observation\n",
      "\n",
      "        # Use asyncio.gather to run multiple tool.arun() calls concurrently\n",
      "        result = await asyncio.gather(\n",
      "            *[_aperform_agent_action(agent_action) for agent_action in actions]\n",
      "        )\n",
      "\n",
      "        return list(result)\n",
      "\n",
      "    def _call(\n",
      "        self,\n",
      "        inputs: Dict[str, str],\n",
      "        run_manager: Optional[CallbackManagerForChainRun] = None,\n",
      "    ) -> Dict[str, Any]:\n",
      "        \"\"\"Run text through and get agent response.\"\"\"\n",
      "        # Construct a mapping of tool name to tool for easy lookup\n",
      "        name_to_tool_map = {tool.name: tool for tool in self.tools}\n",
      "        # We construct a mapping from each tool to a color, used for logging.\n",
      "        color_mapping = get_color_mapping(\n",
      "            [tool.name for tool in self.tools], excluded_colors=[\"green\", \"red\"]\n",
      "        )\n",
      "        intermediate_steps: List[Tuple[AgentAction, str]] = []\n",
      "        # Let's start tracking the number of iterations and time elapsed\n",
      "        iterations = 0\n",
      "        time_elapsed = 0.0\n",
      "        start_time = time.time()\n",
      "        # We now enter the agent loop (until it returns something).\n",
      "        while self._should_continue(iterations, time_elapsed):\n",
      "            next_step_output = self._take_next_step(\n",
      "                name_to_tool_map,\n",
      "                color_mapping,\n",
      "                inputs,\n",
      "                intermediate_steps,\n",
      "                run_manager=run_manager,\n",
      "            )\n",
      "            if isinstance(next_step_output, AgentFinish):\n",
      "                return self._return(\n",
      "                    next_step_output, intermediate_steps, run_manager=run_manager\n",
      "                )\n",
      "\n",
      "            intermediate_steps.extend(next_step_output)\n",
      "            if len(next_step_output) == 1:\n",
      "                next_step_action = next_step_output[0]\n",
      "                # See if tool should return directly\n",
      "                tool_return = self._get_tool_return(next_step_action)\n",
      "                if tool_return is not None:\n",
      "                    return self._return(\n",
      "                        tool_return, intermediate_steps, run_manager=run_manager\n",
      "                    )\n",
      "            iterations += 1\n",
      "            time_elapsed = time.time() - start_time\n",
      "        output = self.agent.return_stopped_response(\n",
      "            self.early_stopping_method, intermediate_steps, **inputs\n",
      "        )\n",
      "        return self._return(output, intermediate_steps, run_manager=run_manager)\n",
      "\n",
      "    async def _acall(\n",
      "        self,\n",
      "        inputs: Dict[str, str],\n",
      "        run_manager: Optional[AsyncCallbackManagerForChainRun] = None,\n",
      "    ) -> Dict[str, str]:\n",
      "        \"\"\"Run text through and get agent response.\"\"\"\n",
      "        # Construct a mapping of tool name to tool for easy lookup\n",
      "        name_to_tool_map = {tool.name: tool for tool in self.tools}\n",
      "        # We construct a mapping from each tool to a color, used for logging.\n",
      "        color_mapping = get_color_mapping(\n",
      "            [tool.name for tool in self.tools], excluded_colors=[\"green\"]\n",
      "        )\n",
      "        intermediate_steps: List[Tuple[AgentAction, str]] = []\n",
      "        # Let's start tracking the number of iterations and time elapsed\n",
      "        iterations = 0\n",
      "        time_elapsed = 0.0\n",
      "        start_time = time.time()\n",
      "        # We now enter the agent loop (until it returns something).\n",
      "        async with asyncio_timeout(self.max_execution_time):\n",
      "            try:\n",
      "                while self._should_continue(iterations, time_elapsed):\n",
      "                    next_step_output = await self._atake_next_step(\n",
      "                        name_to_tool_map,\n",
      "                        color_mapping,\n",
      "                        inputs,\n",
      "                        intermediate_steps,\n",
      "                        run_manager=run_manager,\n",
      "                    )\n",
      "                    if isinstance(next_step_output, AgentFinish):\n",
      "                        return await self._areturn(\n",
      "                            next_step_output,\n",
      "                            intermediate_steps,\n",
      "                            run_manager=run_manager,\n",
      "                        )\n",
      "\n",
      "                    intermediate_steps.extend(next_step_output)\n",
      "                    if len(next_step_output) == 1:\n",
      "                        next_step_action = next_step_output[0]\n",
      "                        # See if tool should return directly\n",
      "                        tool_return = self._get_tool_return(next_step_action)\n",
      "                        if tool_return is not None:\n",
      "                            return await self._areturn(\n",
      "                                tool_return, intermediate_steps, run_manager=run_manager\n",
      "                            )\n",
      "\n",
      "                    iterations += 1\n",
      "                    time_elapsed = time.time() - start_time\n",
      "                output = self.agent.return_stopped_response(\n",
      "                    self.early_stopping_method, intermediate_steps, **inputs\n",
      "                )\n",
      "                return await self._areturn(\n",
      "                    output, intermediate_steps, run_manager=run_manager\n",
      "                )\n",
      "            except TimeoutError:\n",
      "                # stop early when interrupted by the async timeout\n",
      "                output = self.agent.return_stopped_response(\n",
      "                    self.early_stopping_method, intermediate_steps, **inputs\n",
      "                )\n",
      "                return await self._areturn(\n",
      "                    output, intermediate_steps, run_manager=run_manager\n",
      "                )\n",
      "\n",
      "    def _get_tool_return(\n",
      "        self, next_step_output: Tuple[AgentAction, str]\n",
      "    ) -> Optional[AgentFinish]:\n",
      "        \"\"\"Check if the tool is a returning tool.\"\"\"\n",
      "        agent_action, observation = next_step_output\n",
      "        name_to_tool_map = {tool.name: tool for tool in self.tools}\n",
      "        # Invalid tools won't be in the map, so we return False.\n",
      "        if agent_action.tool in name_to_tool_map:\n",
      "            if name_to_tool_map[agent_action.tool].return_direct:\n",
      "                return AgentFinish(\n",
      "                    {self.agent.return_values[0]: observation},\n",
      "                    \"\",\n",
      "                )\n",
      "        return None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(AgentExecutor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fd9d86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
