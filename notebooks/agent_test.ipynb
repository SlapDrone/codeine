{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93f51ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import inspect\n",
    "import typing as ty\n",
    "from functools import wraps\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import aioitertools\n",
    "from langchain.input import get_color_mapping\n",
    "from langchain.agents import AgentExecutor, Tool\n",
    "from langchain.agents.agent import AgentAction, AgentFinish\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForChainRun, Callbacks, CallbackManager, AsyncCallbackManager\n",
    ")\n",
    "from langchain.utilities.asyncio import asyncio_timeout\n",
    "from langchain.load.dump import dumpd\n",
    "sys.path.insert(0, \"..\")\n",
    "from codeine.chatbot import build_chat_engine, service_context\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "chat_engine = build_chat_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "13c28356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_callback_manager_on_set(\n",
    "    setter_method: ty.Callable[..., None]\n",
    ") -> ty.Callable[..., None]:\n",
    "    \"\"\"Decorator to force setters to rebuild callback mgr\"\"\"\n",
    "    @wraps(setter_method)\n",
    "    def wrapper(self: ty.Any, *args: ty.Any, **kwargs: ty.Any) -> None:\n",
    "        setter_method(self, *args, **kwargs)\n",
    "        self.build_callback_manager()\n",
    "    return wrapper\n",
    "\n",
    "class AgentExecutorIterator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        agent_executor: AgentExecutor,\n",
    "        inputs: dict[str, str] | str,\n",
    "        callbacks: Callbacks = None,\n",
    "        *,\n",
    "        tags: list[str] | None = None,\n",
    "        include_run_info: bool = False,\n",
    "        async_: bool = False\n",
    "    ):\n",
    "        self._agent_executor = agent_executor\n",
    "        self.inputs = inputs\n",
    "        self.async_ = async_\n",
    "        # build callback manager on tags setter\n",
    "        self._callbacks = callbacks\n",
    "        self.tags = tags \n",
    "        self.include_run_info = include_run_info\n",
    "        self.run_manager = None\n",
    "    \n",
    "    @property\n",
    "    def inputs(self) -> dict[str, str]:\n",
    "        return self._inputs\n",
    "    \n",
    "    @inputs.setter\n",
    "    def inputs(self, inputs: dict[str, str] | str) -> None:\n",
    "        self._inputs = self.agent_executor.prep_inputs(inputs)\n",
    "    \n",
    "    @property\n",
    "    def callbacks(self):\n",
    "        return self._callbacks\n",
    "    \n",
    "    @property\n",
    "    def tags(self):\n",
    "        return self._tags\n",
    "    \n",
    "    @property\n",
    "    def agent_executor(self):\n",
    "        return self._agent_executor\n",
    "    \n",
    "    @callbacks.setter\n",
    "    @rebuild_callback_manager_on_set\n",
    "    def callbacks(self, callbacks: Callbacks) -> None:\n",
    "        \"\"\"When callbacks are changed after __init__, rebuild callback mgr\"\"\"\n",
    "        self._callbacks = callbacks\n",
    "    \n",
    "    @tags.setter\n",
    "    @rebuild_callback_manager_on_set\n",
    "    def tags(self, tags: list[str] | None) -> None:\n",
    "        \"\"\"When tags are changed after __init__, rebuild callback mgr\"\"\"\n",
    "        self._tags = tags\n",
    "    \n",
    "    @agent_executor.setter\n",
    "    @rebuild_callback_manager_on_set\n",
    "    def agent_executor(self, agent_executor: AgentExecutor) -> None:\n",
    "        self._agent_executor = agent_executor\n",
    "        # force re-prep inputs incase agent_executor's prep_inputs fn changed\n",
    "        self.inputs = self.inputs \n",
    "        \n",
    "    @property\n",
    "    def callback_manager(self) -> AsyncCallbackManager | CallbackManager:\n",
    "        return self._callback_manager\n",
    "    \n",
    "    def build_callback_manager(self) -> None:\n",
    "        CallbackMgr = AsyncCallbackManager if self.async_ else CallbackManager\n",
    "        self._callback_manager = CallbackMgr.configure(\n",
    "            self.callbacks,\n",
    "            self.agent_executor.callbacks,\n",
    "            self.agent_executor.verbose,\n",
    "            self.tags,\n",
    "            self.agent_executor.tags\n",
    "        )        \n",
    "\n",
    "    @property\n",
    "    def name_to_tool_map(self):\n",
    "        return {tool.name: tool for tool in self.agent_executor.tools}\n",
    "    \n",
    "    @property\n",
    "    def color_mapping(self):\n",
    "        return get_color_mapping(\n",
    "            [tool.name for tool in self.agent_executor.tools],\n",
    "            excluded_colors=[\"green\", \"red\"]\n",
    "        )\n",
    "    \n",
    "    def reset(self):\n",
    "        logger.debug(f\"(Re)setting AgentExecutorIterator to fresh state\")\n",
    "        self.intermediate_steps: list[tuple[AgentAction, str]] = []\n",
    "        self.iterations = 0\n",
    "        # maybe better to start these on the first __anext__ call?\n",
    "        self.time_elapsed = 0.0\n",
    "        self.start_time = time.time()\n",
    "        self._final_output = None\n",
    "        \n",
    "    def update_iterations(self):\n",
    "        self.iterations += 1\n",
    "        self.time_elapsed = time.time() - self.start_time\n",
    "        logger.debug(f\"Agent Iterations: {self.iterations} ({self.time_elapsed:.2f}s elapsed)\")\n",
    "        \n",
    "    @property\n",
    "    def final_output(self):\n",
    "        return self._final_output\n",
    "    \n",
    "    @final_output.setter\n",
    "    def _prep_final_outputs(self, output):\n",
    "        pass\n",
    "        \n",
    "    def _process_next_step_output(self, next_step_output, run_manager):\n",
    "        logger.debug(\"Processing output of Agent loop step\")\n",
    "        if isinstance(next_step_output, AgentFinish):\n",
    "            output = self.agent_executor._return(\n",
    "                next_step_output, self.intermediate_steps, run_manager=run_manager\n",
    "            )\n",
    "            self._final_output = output\n",
    "            return output\n",
    "\n",
    "        self.intermediate_steps.extend(next_step_output)\n",
    "        logger.debug(\"Updated intermediate_steps with step output\")\n",
    "        \n",
    "        # Check for tool return\n",
    "        if len(next_step_output) == 1:\n",
    "            next_step_action = next_step_output[0]\n",
    "            tool_return = self.agent_executor._get_tool_return(next_step_action)\n",
    "            if tool_return is not None:\n",
    "                output = self.agent_executor._return(\n",
    "                    tool_return, self.intermediate_steps, run_manager=run_manager\n",
    "                )\n",
    "                self._final_output = output\n",
    "                return output\n",
    "\n",
    "        output = {\"intermediate_steps\": self.intermediate_steps}\n",
    "        return output\n",
    "\n",
    "    async def _aprocess_next_step_output(self, next_step_output, run_manager):\n",
    "        logger.debug(\"Processing output of async Agent loop step\")\n",
    "        if isinstance(next_step_output, AgentFinish):\n",
    "            output = await self.agent_executor._areturn(\n",
    "                next_step_output, self.intermediate_steps, run_manager=run_manager\n",
    "            )\n",
    "            self._final_output = output\n",
    "            return output\n",
    "\n",
    "        self.intermediate_steps.extend(next_step_output)\n",
    "        logger.debug(\"Updated intermediate_steps with step output\")\n",
    "\n",
    "        # Check for tool return\n",
    "        if len(next_step_output) == 1:\n",
    "            next_step_action = next_step_output[0]\n",
    "            tool_return = self.agent_executor._get_tool_return(next_step_action)\n",
    "            if tool_return is not None:\n",
    "                output = await self.agent_executor._areturn(\n",
    "                    tool_return, self.intermediate_steps, run_manager=run_manager\n",
    "                )\n",
    "                self._final_output = output\n",
    "                return output\n",
    "\n",
    "        output = {\"intermediate_steps\": self.intermediate_steps}\n",
    "        return output\n",
    "\n",
    "        \n",
    "    def __iter__(self):\n",
    "        logger.debug(\"Initialising AgentExecutorIterator\")\n",
    "        self.reset()\n",
    "        self.run_manager = self.callback_manager.on_chain_start(\n",
    "            dumpd(self.agent_executor),\n",
    "            self.inputs,\n",
    "        )\n",
    "        return self\n",
    "    \n",
    "    def __aiter__(self):\n",
    "        \"\"\"\n",
    "        N.B. __aiter__ must be a normal method, so need to initialise async run manager \n",
    "        on first __anext__ call where we can await it\n",
    "        \"\"\"\n",
    "        logger.debug(\"Initialising AgentExecutorIterator (async)\")\n",
    "        self.reset()\n",
    "        if self.agent_executor.max_execution_time:\n",
    "            self.timeout_manager = asyncio_timeout(self.agent_executor.max_execution_time)\n",
    "        else:\n",
    "            self.timeout_manager = None\n",
    "        return self\n",
    "    \n",
    "    def __next__(self) -> dict[str, ty.Any]:\n",
    "        \"\"\"\n",
    "        AgentExecutor               AgentExecutorIterator\n",
    "        __call__                    (__iter__ ->) __next__\n",
    "            _call              <=>      _call_next\n",
    "                _take_next_step             _atake_next_step   \n",
    "        \"\"\"\n",
    "        # first step\n",
    "        if not self.iterations:\n",
    "            pass#self._first_step()\n",
    "        # N.B. timeout taken care of by \"_should_continue\" in sync case\n",
    "        return self._call_next()\n",
    "\n",
    "    async def __anext__(self) -> dict[str, ty.Any]:\n",
    "        \"\"\"\n",
    "        AgentExecutor               AgentExecutorIterator\n",
    "        acall                       (__aiter__ ->) __anext__\n",
    "            _acall              <=>     _acall_next\n",
    "                _atake_next_step            _atake_next_step   \n",
    "        \"\"\"\n",
    "        # first step\n",
    "        if not self.iterations:\n",
    "            pass#await self._afirst_step()\n",
    "        if self.run_manager is None:\n",
    "            self.run_manager = await self.callback_manager.on_chain_start(\n",
    "                dumpd(self.agent_executor),\n",
    "                self.inputs,\n",
    "            )\n",
    "        if self.timeout_manager:\n",
    "            async with self.timeout_manager:\n",
    "                try:\n",
    "                    return await self._acall_next()\n",
    "                except Exception as e:\n",
    "                    raise\n",
    "            if self.timeout_manager._timeout.expired:\n",
    "                raise asyncio.TimeoutError(\n",
    "                    \"AgentExecutorIterator exceeded max_execution_time \"\n",
    "                    f\"{self.agent_executor.max_execution_time}\"\n",
    "                )\n",
    "        else:\n",
    "            return await self._acall_next()\n",
    "        \n",
    "    def _chain_end_raise_stopiteration(self, output: ty.Any):\n",
    "        logger.debug(\"Chain end: apply on_chain_end callbacks and stop iteration\")\n",
    "        if self.run_manager:\n",
    "            self.run_manager.on_chain_end(output)\n",
    "        raise StopIteration(output)\n",
    "    \n",
    "    async def _chain_end_raise_stopasynciteration(self, output: ty.Any):\n",
    "        logger.debug(\"Chain end: apply on_chain_end callbacks and stop async iteration\")\n",
    "        if self.run_manager:\n",
    "            await self.run_manager.on_chain_end(output)\n",
    "        raise StopAsyncIteration(output)\n",
    "    \n",
    "    def prep_last_step_outputs(self):\n",
    "        run_manager.on_chain_end(outputs)\n",
    "        final_outputs: dict[str, ty.Any] = self.prep_outputs(\n",
    "            inputs, outputs, return_only_outputs\n",
    "        )\n",
    "        if include_run_info:\n",
    "            final_outputs[RUN_KEY] = RunInfo(run_id=run_manager.run_id)\n",
    "        return final_outputs\n",
    "        raise NotImplementedError(\"!\")\n",
    "        \n",
    "    async def aprep_last_step_outputs(self):\n",
    "        await run_manager.on_chain_end(outputs)\n",
    "        final_outputs: dict[str, ty.Any] = self.prep_outputs(\n",
    "            inputs, outputs, return_only_outputs\n",
    "        )\n",
    "        if include_run_info:\n",
    "            final_outputs[RUN_KEY] = RunInfo(run_id=run_manager.run_id)\n",
    "        raise NotImplementedError(\"!\")\n",
    "    \n",
    "    def _execute_next_step(self):\n",
    "        return self.agent_executor._take_next_step(\n",
    "            self.name_to_tool_map,\n",
    "            self.color_mapping,\n",
    "            self.inputs,\n",
    "            self.intermediate_steps,\n",
    "            run_manager=self.run_manager,\n",
    "        )\n",
    "\n",
    "    async def _execute_next_async_step(self):\n",
    "        return await self.agent_executor._atake_next_step(\n",
    "            self.name_to_tool_map,\n",
    "            self.color_mapping,\n",
    "            self.inputs,\n",
    "            self.intermediate_steps,\n",
    "            run_manager=self.run_manager,\n",
    "        )\n",
    "\n",
    "    def _call_next(self) -> dict[str, ty.Any]:\n",
    "        \"\"\"\n",
    "        If `_should_continue` is True:\n",
    "\n",
    "        compute output from `_take_next_step`\n",
    "\n",
    "        When we hit `AgentFinish` OR determine a direct tool return OR `_should_continue` is false (currently in `process_next_step_output`, in `_call` in original) we:\n",
    "        1. return `self._return(outputs, step, run_manager=...)`\n",
    "        2. This should take us back up to `__next__` (to `__call__` in original) where we:\n",
    "            - `run_manager.on_chain_end(outputs)`\n",
    "            - `final_outputs = self.prep_outputs(inputs, outputs, return_only_outputs)`\n",
    "            - `if include_run_info: final_outputs[RUN_KEY] = RunInfo(...)`\n",
    "            - return `final_outputs`\n",
    "            - (for us: raise `StopIteration(final_outputs)`)\n",
    "\n",
    "        If `_should_continue` is False\n",
    "\n",
    "        We `return_stopped_response` and then `_return` the output\n",
    "        (`return_stopped_response` is for when we hit max iter or time out)\n",
    "        \"\"\"\n",
    "        stop_iteration = (\n",
    "            (self._final_output is not None) or\n",
    "            (not self.agent_executor._should_continue(self.iterations, self.time_elapsed))\n",
    "        )\n",
    "        if stop_iteration:\n",
    "            output = self.agent_executor.agent.return_stopped_response(\n",
    "                self.agent_executor.early_stopping_method,\n",
    "                self.intermediate_steps,\n",
    "                **self.inputs\n",
    "            )\n",
    "            output = self.agent_executor._return(\n",
    "                output, self.intermediate_steps, run_manager=self.run_manager\n",
    "            )\n",
    "            self._chain_end_raise_stopiteration(output)\n",
    "            \n",
    "        next_step_output = self._execute_next_step()\n",
    "        output = self._process_next_step_output(next_step_output, self.run_manager)\n",
    "        self.update_iterations()\n",
    "        return output\n",
    "\n",
    "    async def _acall_next(self) -> dict[str, ty.Any]:\n",
    "        \"\"\"\n",
    "        If `_should_continue` is True AND we haven't timed out:\n",
    "\n",
    "        compute output from `_atake_next_step`\n",
    "\n",
    "        When we hit `AgentFinish` OR determine a direct tool return OR `_should_continue` is false (currently in `process_next_step_output`, in `_call` in original) we:\n",
    "        1. return `self._areturn(outputs, step, run_manager=...)`\n",
    "        2. This should take us back up to `__anext__` (to `_acall` in original) where we:\n",
    "            - `run_manager.on_chain_end(outputs)`\n",
    "            - `final_outputs = self.prep_outputs(inputs, outputs, return_only_outputs)`\n",
    "            - `if include_run_info: final_outputs[RUN_KEY] = RunInfo(...)`\n",
    "            - return `final_outputs`\n",
    "            - (for us: raise `StopIteration(final_outputs)`)\n",
    "\n",
    "        If `_should_continue` is False OR we time out\n",
    "\n",
    "        We `return_stopped_response` and then `_areturn` the output\n",
    "        (`return_stopped_response` is for when we hit max iter or time out)\n",
    "        \"\"\"\n",
    "        stop_iteration = (\n",
    "            (self._final_output is not None) or\n",
    "            (not self.agent_executor._should_continue(self.iterations, self.time_elapsed))\n",
    "        )\n",
    "        if stop_iteration:\n",
    "            output = self.agent_executor.agent.return_stopped_response(\n",
    "                self.agent_executor.early_stopping_method,\n",
    "                self.intermediate_steps,\n",
    "                **self.inputs\n",
    "            )\n",
    "            output = await self.agent_executor._areturn(\n",
    "                output, self.intermediate_steps, run_manager=self.run_manager\n",
    "            )\n",
    "            await self._chain_end_raise_stopasynciteration(output)\n",
    "            \n",
    "        next_step_output = await self._execute_next_async_step()\n",
    "        output = await self._aprocess_next_step_output(next_step_output, self.run_manager)\n",
    "        self.update_iterations()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __call__(\n",
    "    self,\n",
    "    inputs: Union[Dict[str, Any], Any],\n",
    "    return_only_outputs: bool = False,\n",
    "    callbacks: Callbacks = None,\n",
    "    *,\n",
    "    tags: Optional[List[str]] = None,\n",
    "    include_run_info: bool = False,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    REFERENCE IMPLEMENTATION FROM NON-ITERATOR\n",
    "    \n",
    "    Run the logic of this chain and add to output if desired.\n",
    "    For reference: \n",
    "    \n",
    "    for the iterator version, this functionality should all be refactored into:\n",
    "    - __init__ and __iter__ in the case of the setup steps\n",
    "    - EITHER before the first and after the last __next__ calls which return an output \n",
    "      OR at the beginning and end of every __next__ call, but guarded by a condition\n",
    "      in the case of calling _call_next, teardown\n",
    "    - the __next__ call itself in the case of the try/except block\n",
    "      \n",
    "    \n",
    "    _call should map onto _call_next  \n",
    "    \"\"\"\n",
    "    # wanna support modifying iterator before using it so it \n",
    "    # doesn't have to be reconstructed for trivial changes\n",
    "    # factor out to begining of iteration\n",
    "    inputs = self.prep_inputs(inputs) \n",
    "    # factor out to creation of iterator\n",
    "    # pass self.callbacks, self.agent_executor.callbacks\n",
    "    # then can still change self.callbacks after initialisation\n",
    "    callback_manager = CallbackManager.configure(\n",
    "        callbacks, self.callbacks, self.verbose, tags, self.tags\n",
    "    ) \n",
    "    # factor out to creation of iterator\n",
    "    new_arg_supported = inspect.signature(self._call).parameters.get(\"run_manager\")\n",
    "    # beginning of iteration (on first __next__ call)\n",
    "    run_manager = callback_manager.on_chain_start(\n",
    "        dumpd(self),\n",
    "        inputs,\n",
    "    )\n",
    "    # try/except goes into __next__ and wraps _call_next\n",
    "    try:\n",
    "        outputs = (\n",
    "            self._call(inputs, run_manager=run_manager)\n",
    "            if new_arg_supported\n",
    "            else self._call(inputs)\n",
    "        )\n",
    "    except (KeyboardInterrupt, Exception) as e:\n",
    "        run_manager.on_chain_error(e)\n",
    "        raise e\n",
    "    # here til end: end of iteration\n",
    "    run_manager.on_chain_end(outputs)\n",
    "    final_outputs: Dict[str, Any] = self.prep_outputs(\n",
    "        inputs, outputs, return_only_outputs\n",
    "    )\n",
    "    if include_run_info:\n",
    "        final_outputs[RUN_KEY] = RunInfo(run_id=run_manager.run_id)\n",
    "    return final_outputs\n",
    "\n",
    "async def acall(\n",
    "    self,\n",
    "    inputs: Union[Dict[str, Any], Any],\n",
    "    return_only_outputs: bool = False,\n",
    "    callbacks: Callbacks = None,\n",
    "    *,\n",
    "    tags: Optional[List[str]] = None,\n",
    "    include_run_info: bool = False,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Run the logic of this chain and add to output if desired.\n",
    "\n",
    "    Args:\n",
    "        inputs: Dictionary of inputs, or single input if chain expects\n",
    "            only one param.\n",
    "        return_only_outputs: boolean for whether to return only outputs in the\n",
    "            response. If True, only new keys generated by this chain will be\n",
    "            returned. If False, both input keys and new keys generated by this\n",
    "            chain will be returned. Defaults to False.\n",
    "        callbacks: Callbacks to use for this chain run. If not provided, will\n",
    "            use the callbacks provided to the chain.\n",
    "        include_run_info: Whether to include run info in the response. Defaults\n",
    "            to False.\n",
    "    \"\"\"\n",
    "    inputs = self.prep_inputs(inputs)\n",
    "    callback_manager = AsyncCallbackManager.configure(\n",
    "        callbacks, self.callbacks, self.verbose, tags, self.tags\n",
    "    )\n",
    "    new_arg_supported = inspect.signature(self._acall).parameters.get(\"run_manager\")\n",
    "    run_manager = await callback_manager.on_chain_start(\n",
    "        dumpd(self),\n",
    "        inputs,\n",
    "    )\n",
    "    try:\n",
    "        outputs = (\n",
    "            await self._acall(inputs, run_manager=run_manager)\n",
    "            if new_arg_supported\n",
    "            else await self._acall(inputs)\n",
    "        )\n",
    "    except (KeyboardInterrupt, Exception) as e:\n",
    "        await run_manager.on_chain_error(e)\n",
    "        raise e\n",
    "    await run_manager.on_chain_end(outputs)\n",
    "    final_outputs: Dict[str, Any] = self.prep_outputs(\n",
    "        inputs, outputs, return_only_outputs\n",
    "    )\n",
    "    if include_run_info:\n",
    "        final_outputs[RUN_KEY] = RunInfo(run_id=run_manager.run_id)\n",
    "    return final_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dfc5c1",
   "metadata": {},
   "source": [
    "in `_(a)next_step`:\n",
    "\n",
    "If `_should_continue` is True AND we haven't timed out (async):\n",
    "\n",
    "When we hit `AgentFinish` OR determine a direct tool return OR `_should_continue` is false (currently in `process_next_step_output`, in `_call` in original) we:\n",
    "1. return `self._return(outputs, step, run_manager=...)`\n",
    "2. This should take us back up to `__next__` (to `__call__` in original) where we:\n",
    "    - `run_manager.on_chain_end(outputs)`\n",
    "    - `final_outputs = self.prep_outputs(inputs, outputs, return_only_outputs)`\n",
    "    - `if include_run_info: final_outputs[RUN_KEY] = RunInfo(...)`\n",
    "    - return `final_outputs`\n",
    "    - (for us: raise `StopIteration(final_outputs)`)\n",
    "    \n",
    "If `_should_continue` is False OR we time out (async)\n",
    "\n",
    "We `return_stopped_response` and then `_return`/`_areturn` the output\n",
    "(`return_stopped_response` is for when we hit max iter or time out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "95cba515",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAgentExecutor(AgentExecutor):\n",
    "    def __call__(\n",
    "        self,\n",
    "        inputs: dict[str, str] | ty.Any,\n",
    "        return_only_outputs: bool = False,\n",
    "        callbacks: Callbacks = None,\n",
    "        *,\n",
    "        tags: list[str] | None = None,\n",
    "        include_run_info: bool = False,\n",
    "        iterator: bool = False,\n",
    "        async_: bool = False,\n",
    "    ) -> dict[str, ty.Any]:\n",
    "        if iterator:\n",
    "            return AgentExecutorIterator(\n",
    "                self,\n",
    "                inputs,\n",
    "                callbacks,\n",
    "                tags=tags,\n",
    "                include_run_info=include_run_info,\n",
    "                async_=async_\n",
    "            )    \n",
    "        else:\n",
    "            return super().__call__(\n",
    "                inputs,\n",
    "                return_only_outputs,\n",
    "                callbacks,\n",
    "                tags=tags,\n",
    "                include_run_info=include_run_info\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "da1b52e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signature (inputs: Union[dict[str, str], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: list[str] | None = None, include_run_info: bool = False, iterator: bool = False, async_: bool = False) -> dict[str, typing.Any]>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor = MyAgentExecutor.from_agent_and_tools(\n",
    "    agent=chat_engine._agent.agent,\n",
    "    tools=chat_engine._agent.tools,\n",
    "    callback_manager=chat_engine._agent.callback_manager\n",
    ")\n",
    "agent_executor.memory = chat_engine._agent.memory\n",
    "inspect.signature(agent_executor.__call__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d642cf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 5 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 2855 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** STEP:\n",
      "{'intermediate_steps': [(AgentAction(tool='Codeine Source Code Search', tool_input='Codeine source code structure', log='{\\n    \"action\": \"Codeine Source Code Search\",\\n    \"action_input\": \"Codeine source code structure\"\\n}'), 'The Codeine source code is structured into multiple files, including presets.py, chatbot.py, utils.py, README.md, and LICENSE. The presets.py file contains a theme for the Gradio frontend, while chatbot.py contains code for building a chat engine. The utils.py file contains various utility functions, including one for converting Markdown to HTML with syntax highlighting. The README.md file provides installation instructions and information about the project, while the LICENSE file outlines the permissions and conditions for using the Codeine source code.')]}\n",
      "***\n",
      "*** STEP:\n",
      "{'output': 'The Codeine source code is structured into multiple files, including presets.py, chatbot.py, utils.py, README.md, and LICENSE. The presets.py file contains a theme for the Gradio frontend, while chatbot.py contains code for building a chat engine. The utils.py file contains various utility functions, including one for converting Markdown to HTML with syntax highlighting. The README.md file provides installation instructions and information about the project, while the LICENSE file outlines the permissions and conditions for using the Codeine source code.'}\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "inputs = \"Tell me about the structure of the codeine source code\"\n",
    "\n",
    "for step in agent_executor(inputs=inputs, iterator=True):\n",
    "    print(\"*** STEP:\")\n",
    "    print(step)\n",
    "    print(\"***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "90ffdfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1176 request_id=07d8a8ef1482b15610960dd5a159c465 response_code=200\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 5 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 2855 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** STEP:\n",
      "{'intermediate_steps': [(AgentAction(tool='Codeine Source Code Search', tool_input='Codeine source code structure', log='{\\n    \"action\": \"Codeine Source Code Search\",\\n    \"action_input\": \"Codeine source code structure\"\\n}'), 'The Codeine source code is structured into multiple files, including presets.py, chatbot.py, utils.py, README.md, and LICENSE. The presets.py file contains a theme for the Gradio frontend, while chatbot.py contains code for building a chat engine. The utils.py file contains various utility functions, including one for converting Markdown to HTML with syntax highlighting. The README.md file provides installation instructions and information about the project, while the LICENSE file outlines the permissions and conditions for using the Codeine source code.')]}\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4245 request_id=3ef28d90a3828e8a375d4dea8d3c1a4e response_code=200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** STEP:\n",
      "{'output': 'The Codeine source code is structured into multiple files, including presets.py, chatbot.py, utils.py, README.md, and LICENSE. The presets.py file contains a theme for the Gradio frontend, while chatbot.py contains code for building a chat engine. The utils.py file contains various utility functions, including one for converting Markdown to HTML with syntax highlighting. The README.md file provides installation instructions and information about the project, while the LICENSE file outlines the permissions and conditions for using the Codeine source code.'}\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "inputs = \"Tell me about the structure of the codeine source code\"\n",
    "async_mae_iter = agent_executor(inputs=inputs, iterator=True, async_=True)\n",
    "async_mae_iter.inputs = \"Tell me about ze structure of the codeine source code\"\n",
    "async_mae_iter.agent_executor = async_mae_iter.agent_executor\n",
    "async for step in async_mae_iter:\n",
    "    print(\"*** STEP:\")\n",
    "    print(step)\n",
    "    print(\"***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5203b03c",
   "metadata": {},
   "source": [
    "Two pieces of code on which design/refactor is based:\n",
    "\n",
    "Original AgentExecutor (non-iterator version) for which we want to mimic the logic\n",
    "https://github.com/hwchase17/langchain/blob/2da1aab50b43c63c7a9a9553b7290230c44604bc/langchain/agents/agent.py#L620\n",
    "\n",
    "The inherited `__call__` and `acall` methods from Chain:\n",
    "https://github.com/hwchase17/langchain/blob/22af93d8516a4ecc05e2c814ad5660c0b6427625/langchain/chains/base.py#L126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787f0a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def todo(self):\n",
    "    \"\"\"\n",
    "    INTEGRATE THIS LOGIC (missing from current implementation, need \n",
    "    to figure out how to structure it)\"\"\"\n",
    "    try:\n",
    "        outputs = (\n",
    "            self._call(inputs, run_manager=run_manager)\n",
    "            if new_arg_supported\n",
    "            else self._call(inputs)\n",
    "        )\n",
    "    except (KeyboardInterrupt, Exception) as e:\n",
    "        run_manager.on_chain_error(e)\n",
    "        raise e\n",
    "    run_manager.on_chain_end(outputs)\n",
    "    final_outputs: Dict[str, Any] = self.prep_outputs(\n",
    "        inputs, outputs, return_only_outputs\n",
    "    )\n",
    "    if include_run_info:\n",
    "        final_outputs[RUN_KEY] = RunInfo(run_id=run_manager.run_id)\n",
    "    return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37775a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1ba20a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87c2dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c700346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aeee67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c395a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b762e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9969233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45690111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc1f30a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa50c02f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbba7a17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cac8bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7889da17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f330e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c1850c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d33600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7869aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1654ef42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0fc9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d8635937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b85ade33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__aiter__',\n",
       " '__anext__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__next__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_anext_step',\n",
       " '_aprocess_next_step_output',\n",
       " '_chain_end_raise_stopasynciteration',\n",
       " '_chain_end_raise_stopiteration',\n",
       " '_next_step',\n",
       " '_process_next_step_output',\n",
       " 'agent_executor',\n",
       " 'async_',\n",
       " 'build_callback_manager',\n",
       " 'callback_manager',\n",
       " 'callbacks',\n",
       " 'color_mapping',\n",
       " 'include_run_info',\n",
       " 'inputs',\n",
       " 'name_to_tool_map',\n",
       " 'reset',\n",
       " 'update_iterations']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(async_mae_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ba91b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8685ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95423e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b23d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3aa85b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137d4ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d1acda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c46341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6c4d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedd9fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189030c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f78692f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa8cfa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ab9759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67013709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e8eecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b03db6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ec49b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def __aiter__(self):\n",
    "    # Initialize instance variables for inputs, run_manager, iterations, time_elapsed, and start_time\n",
    "    self.inputs = ...  # Pass the inputs when initializing the AgentExecutor\n",
    "    self.run_manager = ...  # Pass the run_manager when initializing the AgentExecutor\n",
    "    self.iterations = 0\n",
    "    self.time_elapsed = 0.0\n",
    "    self.start_time = time.time()\n",
    "    self.intermediate_steps = []\n",
    "    return self\n",
    "AgentExecutor.__aiter__ = __aiter__\n",
    "\n",
    "\n",
    "async def __anext__(self) -> Dict[str, Any]:\n",
    "    \"\"\"Async iterator for hooking into agent steps\"\"\"\n",
    "    # Initialization should be done in __aiter__ or another method\n",
    "    # and instance variables should be used for inputs, run_manager, iterations, and time_elapsed\n",
    "\n",
    "    # Construct a mapping of tool name to tool for easy lookup\n",
    "    name_to_tool_map = {tool.name: tool for tool in self.tools}\n",
    "    # We construct a mapping from each tool to a color, used for logging.\n",
    "    color_mapping = get_color_mapping(\n",
    "        [tool.name for tool in self.tools], excluded_colors=[\"green\", \"red\"]\n",
    "    )\n",
    "    intermediate_steps: List[Tuple[AgentAction, str]] = []\n",
    "    # Let's start tracking the number of iterations and time elapsed\n",
    "    iterations = 0\n",
    "    time_elapsed = 0.0\n",
    "    start_time = time.time()\n",
    "    # Agent loop\n",
    "    if not self._should_continue(iterations, time_elapsed):\n",
    "        output = self.agent.return_stopped_response(\n",
    "            self.early_stopping_method, self.intermediate_steps, **self.inputs\n",
    "        )\n",
    "        output = await self._areturn(\n",
    "            output, self.intermediate_steps, run_manager=self.run_manager\n",
    "        )\n",
    "        raise StopAsyncIteration(output)\n",
    "\n",
    "    next_step_output = await self._atake_next_step(\n",
    "        name_to_tool_map,\n",
    "        color_mapping,\n",
    "        inputs,\n",
    "        intermediate_steps,\n",
    "        run_manager=run_manager,\n",
    "    )\n",
    "\n",
    "    if isinstance(next_step_output, AgentFinish):\n",
    "        output = await self._areturn(\n",
    "            next_step_output, intermediate_steps, run_manager=run_manager\n",
    "        )\n",
    "        raise StopAsyncIteration(output)\n",
    "\n",
    "    intermediate_steps.extend(next_step_output)\n",
    "    \n",
    "    # Check for tool return\n",
    "    if len(next_step_output) == 1:\n",
    "        next_step_action = next_step_output[0]\n",
    "        tool_return = self._get_tool_return(next_step_action)\n",
    "        if tool_return is not None:\n",
    "            output = await self._areturn(\n",
    "                tool_return, intermediate_steps, run_manager=run_manager\n",
    "            )\n",
    "            raise StopAsyncIteration(output)\n",
    "            \n",
    "    output = {\"intermediate_steps\": intermediate_steps}\n",
    "\n",
    "    iterations += 1\n",
    "    time_elapsed = time.time() - start_time\n",
    "\n",
    "    return output\n",
    "\n",
    "AgentExecutor.__anext__ = __anext__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dab47e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def intermediate_steps_generator(\n",
    "    self,\n",
    "    inputs: dict[str, str],\n",
    "    run_manager: ty.Optional[AsyncCallbackManagerForChainRun] = None,\n",
    ") -> ty.AsyncIterator[tuple[AgentAction, str]]:\n",
    "    \"\"\"Generator function that yields intermediate steps (thoughts, actions, and observations).\"\"\"\n",
    "\n",
    "    logger.debug(\"Starting generator\")\n",
    "\n",
    "    name_to_tool_map = {tool.name: tool for tool in self.tools}\n",
    "    color_mapping = get_color_mapping(\n",
    "        [tool.name for tool in self.tools], excluded_colors=[\"green\"]\n",
    "    )\n",
    "    intermediate_steps: List[Tuple[AgentAction, str]] = []\n",
    "    iterations = 0\n",
    "    time_elapsed = 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    async with asyncio_timeout(self.max_execution_time):\n",
    "        try:\n",
    "            while self._should_continue(iterations, time_elapsed):\n",
    "                logger.debug(f\"Iteration {iterations}\")\n",
    "\n",
    "                next_step_output = await self._atake_next_step(\n",
    "                    name_to_tool_map,\n",
    "                    color_mapping,\n",
    "                    inputs,\n",
    "                    intermediate_steps,\n",
    "                    run_manager=run_manager,\n",
    "                )\n",
    "                if isinstance(next_step_output, AgentFinish):\n",
    "                    # Yield the final answer - Do I want to do this here?\n",
    "                    final_answer = next_step_output.return_values[\"output\"]\n",
    "                    yield next_step_output, final_answer\n",
    "                    logger.debug(\"Agent finished\")\n",
    "                    break\n",
    "\n",
    "                intermediate_steps.extend(next_step_output)\n",
    "                if len(next_step_output) == 1:\n",
    "                    next_step_action = next_step_output[0]\n",
    "                    tool_return = self._get_tool_return(next_step_action)\n",
    "                    if tool_return is not None:\n",
    "                        logger.debug(\"Tool returned\")\n",
    "                        break\n",
    "\n",
    "                # Yield the latest intermediate step(s)\n",
    "                for step_output in next_step_output:\n",
    "                    logger.debug(f\"Yielding step: {step_output}\")\n",
    "                    yield step_output\n",
    "\n",
    "                iterations += 1\n",
    "                time_elapsed = time.time() - start_time\n",
    "        except TimeoutError:\n",
    "            logger.debug(\"TimeoutError\")\n",
    "            pass\n",
    "    logger.debug(\"Generator finished\")\n",
    "\n",
    "AgentExecutor.intermediate_steps_generator = intermediate_steps_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b193db9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a6005b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def _acall(\n",
    "    self,\n",
    "    inputs: dict[str, str],\n",
    "    run_manager: ty.Optional[AsyncCallbackManagerForChainRun] = None,\n",
    ") -> dict[str, str]:\n",
    "    \"\"\"Run text through and get agent response.\"\"\"\n",
    "    intermediate_steps: list[tuple[AgentAction, str]] = []\n",
    "\n",
    "    async for step in self.intermediate_steps_generator(inputs, run_manager):\n",
    "        intermediate_steps.append(step)\n",
    "\n",
    "    output = self.agent.return_stopped(intermediate_steps)\n",
    "    return output\n",
    "\n",
    "AgentExecutor._acall = _acall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fe9af6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def _atake_next_step(\n",
    "    self,\n",
    "    name_to_tool_map: dict[str, Tool],\n",
    "    color_mapping: dict[str, str],\n",
    "    inputs: dict[str, str],\n",
    "    intermediate_steps: list[tuple[AgentAction, str]],\n",
    "    run_manager: ty.Optional[AsyncCallbackManagerForChainRun] = None,\n",
    ") -> list[tuple[AgentAction, str]] | AgentFinish:\n",
    "    \"\"\"Take a single step in the thought-action-observation loop.\"\"\"\n",
    "\n",
    "    logger.debug(\"Taking next step\")\n",
    "\n",
    "    try:\n",
    "        # Call the LLM to see what to do.\n",
    "        output = await self.agent.aplan(\n",
    "            intermediate_steps,\n",
    "            callbacks=run_manager.get_child() if run_manager else None,\n",
    "            **inputs,\n",
    "        )\n",
    "    except OutputParserException as e:\n",
    "        if isinstance(self.handle_parsing_errors, bool):\n",
    "            raise_error = not self.handle_parsing_errors\n",
    "        else:\n",
    "            raise_error = False\n",
    "        if raise_error:\n",
    "            raise e\n",
    "        text = str(e)\n",
    "        if isinstance(self.handle_parsing_errors, bool):\n",
    "            if e.send_to_llm:\n",
    "                observation = str(e.observation)\n",
    "                text = str(e.llm_output)\n",
    "            else:\n",
    "                observation = \"Invalid or incomplete response\"\n",
    "        elif isinstance(self.handle_parsing_errors, str):\n",
    "            observation = self.handle_parsing_errors\n",
    "        elif callable(self.handle_parsing_errors):\n",
    "            observation = self.handle_parsing_errors(e)\n",
    "        else:\n",
    "            raise ValueError(\"Got unexpected type of `handle_parsing_errors`\")\n",
    "        output = AgentAction(\"_Exception\", observation, text)\n",
    "        if run_manager:\n",
    "            run_manager.on_agent_action(output, color=\"green\")\n",
    "        tool_run_kwargs = self.agent.tool_run_logging_kwargs()\n",
    "        observation = ExceptionTool().run(\n",
    "            output.tool_input,\n",
    "            verbose=self.verbose,\n",
    "            color=None,\n",
    "            callbacks=run_manager.get_child() if run_manager else None,\n",
    "            **tool_run_kwargs,\n",
    "        )\n",
    "        return [(output, observation)]\n",
    "\n",
    "    logger.debug(f\"Agent output: {output}\")\n",
    "\n",
    "    # If the tool chosen is the finishing tool, then we end and return.\n",
    "    if isinstance(output, AgentFinish):\n",
    "        return output\n",
    "    actions: List[AgentAction]\n",
    "    if isinstance(output, AgentAction):\n",
    "        actions = [output]\n",
    "    else:\n",
    "        actions = output\n",
    "\n",
    "    async def _aperform_agent_action(\n",
    "        agent_action: AgentAction,\n",
    "    ) -> tuple[AgentAction, str]:\n",
    "        if run_manager:\n",
    "            await run_manager.on_agent_action(\n",
    "                agent_action, verbose=self.verbose, color=\"green\"\n",
    "            )\n",
    "        # Otherwise we lookup the tool\n",
    "        if agent_action.tool in name_to_tool_map:\n",
    "            tool = name_to_tool_map[agent_action.tool]\n",
    "            return_direct = tool.return_direct\n",
    "            color = color_mapping[agent_action.tool]\n",
    "            tool_run_kwargs = self.agent.tool_run_logging_kwargs()\n",
    "            if return_direct:\n",
    "                tool_run_kwargs[\"llm_prefix\"] = \"\"\n",
    "            # We then call the tool on the tool input to get an observation\n",
    "            observation = await tool.arun(\n",
    "                agent_action.tool_input,\n",
    "                verbose=self.verbose,\n",
    "                color=color,\n",
    "                callbacks=run_manager.get_child() if run_manager else None,\n",
    "                **tool_run_kwargs,\n",
    "            )\n",
    "        else:\n",
    "            tool_run_kwargs = self.agent.tool_run_logging_kwargs()\n",
    "            observation = await InvalidTool().arun(\n",
    "                agent_action.tool,\n",
    "                verbose=self.verbose,\n",
    "                color=None,\n",
    "                callbacks=run_manager.get_child() if run_manager else None,\n",
    "                **tool_run_kwargs,\n",
    "            )\n",
    "        return agent_action, observation\n",
    "\n",
    "    # Use asyncio.gather to run multiple tool.arun() calls concurrently\n",
    "    result = await asyncio.gather(\n",
    "        *[_aperform_agent_action(agent_action) for agent_action in actions]\n",
    "    )\n",
    "\n",
    "    return list(result)\n",
    "\n",
    "\n",
    "AgentExecutor._atake_next_step = _atake_next_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18b76470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59408dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signature (inputs: Union[dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: list[str] | None = None, include_run_info: bool = False, iterator: bool = False, async_: bool = False) -> dict[str, typing.Any]>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c10b56d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CallbackManager' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmae\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhey\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 14\u001b[0m, in \u001b[0;36mMyAgentExecutor.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info, iterator, async_)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m      4\u001b[0m     inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, ty\u001b[38;5;241m.\u001b[39mAny] \u001b[38;5;241m|\u001b[39m ty\u001b[38;5;241m.\u001b[39mAny,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     async_: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, ty\u001b[38;5;241m.\u001b[39mAny]:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m iterator:\n\u001b[0;32m---> 14\u001b[0m         callback_manager \u001b[38;5;241m=\u001b[39m \u001b[43mCallbackManager\u001b[49m\u001b[38;5;241m.\u001b[39mconfigure(\n\u001b[1;32m     15\u001b[0m             callbacks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, tags, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[1;32m     16\u001b[0m         )\n\u001b[1;32m     17\u001b[0m         run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m     18\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m     19\u001b[0m             inputs,\n\u001b[1;32m     20\u001b[0m         )\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m AgentExecutorIterator(\u001b[38;5;28mself\u001b[39m, inputs, callbacks, async_\u001b[38;5;241m=\u001b[39masync_)    \n",
      "\u001b[0;31mNameError\u001b[0m: name 'CallbackManager' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21709a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_engine._agent.callback_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c908b5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Config',\n",
       " '__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__class_vars__',\n",
       " '__config__',\n",
       " '__custom_root_type__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__exclude_fields__',\n",
       " '__fields__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_validators__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__include_fields__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__json_encoder__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__post_root_validators__',\n",
       " '__pre_root_validators__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__schema_cache__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__signature__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__try_update_forward_refs__',\n",
       " '__validators__',\n",
       " '_abc_impl',\n",
       " '_acall',\n",
       " '_areturn',\n",
       " '_atake_next_step',\n",
       " '_calculate_keys',\n",
       " '_call',\n",
       " '_chain_type',\n",
       " '_copy_and_set_values',\n",
       " '_decompose_class',\n",
       " '_enforce_dict_if_root',\n",
       " '_get_tool_return',\n",
       " '_get_value',\n",
       " '_init_private_attributes',\n",
       " '_iter',\n",
       " '_return',\n",
       " '_should_continue',\n",
       " '_take_next_step',\n",
       " '_validate_inputs',\n",
       " '_validate_outputs',\n",
       " 'acall',\n",
       " 'agent',\n",
       " 'apply',\n",
       " 'arun',\n",
       " 'callback_manager',\n",
       " 'callbacks',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'dict',\n",
       " 'early_stopping_method',\n",
       " 'from_agent_and_tools',\n",
       " 'from_orm',\n",
       " 'handle_parsing_errors',\n",
       " 'input_keys',\n",
       " 'intermediate_steps_generator',\n",
       " 'json',\n",
       " 'lc_attributes',\n",
       " 'lc_kwargs',\n",
       " 'lc_namespace',\n",
       " 'lc_secrets',\n",
       " 'lc_serializable',\n",
       " 'lookup_tool',\n",
       " 'max_execution_time',\n",
       " 'max_iterations',\n",
       " 'memory',\n",
       " 'output_keys',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'prep_inputs',\n",
       " 'prep_outputs',\n",
       " 'raise_deprecation',\n",
       " 'return_intermediate_steps',\n",
       " 'run',\n",
       " 'save',\n",
       " 'save_agent',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'set_verbose',\n",
       " 'tags',\n",
       " 'to_json',\n",
       " 'to_json_not_implemented',\n",
       " 'tools',\n",
       " 'update_forward_refs',\n",
       " 'validate',\n",
       " 'validate_return_direct_tool',\n",
       " 'validate_tools',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(chat_engine._agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1646da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_engine._agent.return_intermediate_steps = True\n",
    "chat_engine._agent.verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "291a2f38",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Chain.__call__() missing 1 required positional argument: 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mchat_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Chain.__call__() missing 1 required positional argument: 'inputs'"
     ]
    }
   ],
   "source": [
    "chat_engine._agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddc1c7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1362 request_id=08c2551c8e6d35c00324fb017c8f328d response_code=200\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 4 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 4427 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "INFO:root:==========================================\n",
      "INFO:root:Step: 0\n",
      "INFO:root:Action: AgentAction(tool='Codeine Source Code Search', tool_input='TinyViT', log='{\\n    \"action\": \"Codeine Source Code Search\",\\n    \"action_input\": \"TinyViT\"\\n}')\n",
      "INFO:root:Text: TinyViT is a neural network architecture designed for vision tasks, with a focus on being small and efficient. It consists of multiple transformer blocks with different depths, number of heads, and window sizes, and uses a distillation framework to transfer knowledge from larger models to smaller ones. The TinyViT model has 21 million parameters and is designed for tasks such as neural architecture search, tiny transformer design, and model compression projects. The code snippet provided shows the initialization of a TinyViT model with specific parameters such as image size, number of classes, embedding dimensions, and drop rates.\n",
      "INFO:root:==========================================\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4255 request_id=dafbf95ffc0bfe776bcba95a4b91c38d response_code=200\n",
      "INFO:root:==========================================\n",
      "INFO:root:Step: 1\n",
      "INFO:root:Action: AgentFinish(return_values={'output': 'TinyViT is a small and efficient neural network architecture designed for vision tasks. It consists of multiple transformer blocks with different depths, number of heads, and window sizes, and uses a distillation framework to transfer knowledge from larger models to smaller ones. The TinyViT model has 21 million parameters and is designed for tasks such as neural architecture search, tiny transformer design, and model compression projects.'}, log='{\\n    \"action\": \"Final Answer\",\\n    \"action_input\": \"TinyViT is a small and efficient neural network architecture designed for vision tasks. It consists of multiple transformer blocks with different depths, number of heads, and window sizes, and uses a distillation framework to transfer knowledge from larger models to smaller ones. The TinyViT model has 21 million parameters and is designed for tasks such as neural architecture search, tiny transformer design, and model compression projects.\"\\n}')\n",
      "INFO:root:Text: TinyViT is a small and efficient neural network architecture designed for vision tasks. It consists of multiple transformer blocks with different depths, number of heads, and window sizes, and uses a distillation framework to transfer knowledge from larger models to smaller ones. The TinyViT model has 21 million parameters and is designed for tasks such as neural architecture search, tiny transformer design, and model compression projects.\n",
      "INFO:root:==========================================\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"input\": \"How does TinyViT work?\",\n",
    "    \"chat_history\" : []\n",
    "}\n",
    "\n",
    "async for ix, step in aioitertools.enumerate(chat_engine._agent.intermediate_steps_generator(\n",
    "    inputs,\n",
    ")):\n",
    "    logging.info(\"==========================================\")\n",
    "    logging.info(f\"Step: {ix}\")\n",
    "    if isinstance(step, str): # agent is finished\n",
    "        text = step\n",
    "    else: # agent has a tool to use\n",
    "        action, text = step\n",
    "        logging.info(f\"Action: {action}\")\n",
    "    logging.info(f\"Text: {text}\")\n",
    "    logging.info(\"==========================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "167867ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Training TinyViT, a smaller version of the Vision Transformer (ViT) model, involves a similar process to training the original ViT. The main steps include: 1. Preparing a dataset of images and their corresponding labels. 2. Initializing the TinyViT model with a smaller architecture compared to the original ViT. 3. Feeding the images through the model and computing the loss based on the model's predictions and the true labels. 4. Updating the model's weights using an optimization algorithm, such as Adam or SGD, to minimize the loss. 5. Repeating steps 3 and 4 for multiple epochs until the model converges or reaches a satisfactory performance level. The primary difference between TinyViT and the original ViT is the model's size, which makes TinyViT more efficient and faster to train, while still maintaining competitive performance on various computer vision tasks.\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f3b236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
